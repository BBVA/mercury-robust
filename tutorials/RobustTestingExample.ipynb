{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00b1059",
   "metadata": {
    "id": "c00b1059"
   },
   "source": [
    "# Robust ML Testing (Tests Example)\n",
    "\n",
    "This notebook shows several automatic tests which can be included within your ML pipeline in order to ensure robustness against bugs, drift or oversights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19c5cf4",
   "metadata": {
    "id": "b19c5cf4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82498f8b",
   "metadata": {
    "id": "82498f8b"
   },
   "outputs": [],
   "source": [
    "from mercury.dataschema import DataSchema\n",
    "from mercury.dataschema.feature import FeatType\n",
    "\n",
    "from mercury.robust.data_tests import (\n",
    "    SameSchemaTest, \n",
    "    DriftTest,\n",
    "    LinearCombinationsTest,\n",
    "    LabelLeakingTest,\n",
    "    NoisyLabelsTest,\n",
    "    CohortPerformanceTest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673edaeb",
   "metadata": {
    "id": "673edaeb"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "Here we will use the **Titanic** and **Tips** datasets in some of the robust tests. We will be manually altering it for running the different tests for showing how they can detect failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5699f26",
   "metadata": {
    "id": "b5699f26"
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff618629",
   "metadata": {
    "id": "ff618629"
   },
   "outputs": [],
   "source": [
    "#titanic = Titanic().load()\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "isna_deck = titanic.deck.isna()\n",
    "titanic['class'] = titanic['class'].astype(str)\n",
    "titanic['deck'] = titanic['deck'].astype(str)\n",
    "titanic['who'] = titanic['who'].astype(str)\n",
    "titanic.loc[isna_deck, 'deck'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d754b505",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d754b505",
    "outputId": "48de28df-0d79-4098-99ae-546e9d4e5c81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f1b31",
   "metadata": {
    "id": "275f1b31"
   },
   "source": [
    "## Robust Test\n",
    "\n",
    "Next, we show examples of different tests. You can follow the tutorial executing all the test or you can jump to the tests that you are more interested:\n",
    "\n",
    "#### [Same Schema Test](#same_schema)\n",
    "#### [Data Drift Test](#data_drift)\n",
    "#### [Linear Combinations Test](#linear_combinations)\n",
    "#### [Label Leaking Test](#label_leaking)\n",
    "#### [Noisy Labels Test](#noisy_labels)\n",
    "#### [Cohort Performance Test](#cohort_performance)\n",
    "#### [Model Reproducibility Test](#model_reproducibility)\n",
    "#### [Model Simplicity Test](#model_simplicity)\n",
    "#### [Drift Resistance Test](#drift_resistance)\n",
    "#### [Sample Leaking Test](#sample_leaking)\n",
    "#### [Feature Checker Test](#feature_checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181badf3",
   "metadata": {
    "id": "181badf3"
   },
   "source": [
    "<a id=\"same_schema\"></a>\n",
    "### Same Schema Test example\n",
    "\n",
    "This test ensures a dataset (or new batch of data) shares the same schema as an original dataset. If the schema of the new data changes, for any reason (e.g. errors/changes on ETL processes), the test will detect it and will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c38f513",
   "metadata": {
    "id": "9c38f513"
   },
   "outputs": [],
   "source": [
    "titanic2 = titanic.copy() # Make an unaltered copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca60bf0",
   "metadata": {
    "id": "dca60bf0"
   },
   "source": [
    "For this test, we first need to have an already built **Mercury's `DataSchema`** object with the schema of the original dataset (e.g. training data). Note it doesn't need to be generated on every test, as it can also be serialized and loaded back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0817f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd0817f8",
    "outputId": "b858597e-4907-4956-de61-4bb8ee6903c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature pclass converted to Categorical because percentage of unique values 0.003367003367003367 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature sibsp converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature parch converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Schema of the original dataset\n",
    "schma_reference = DataSchema().generate(titanic).calculate_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5101bcc",
   "metadata": {
    "id": "d5101bcc"
   },
   "source": [
    "Create and execute this single test. It will pass because the original schema has not been altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d117f20a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "d117f20a",
    "outputId": "c35b092a-1afb-4169-f6dd-6da6d632c053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature pclass converted to Categorical because percentage of unique values 0.003367003367003367 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature sibsp converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature parch converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SameSchemaTest(titanic2, schma_reference).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000b12",
   "metadata": {
    "id": "b3000b12"
   },
   "source": [
    "Alter new dataset. We simulate we lose one of the columns... (however, this test will also check feature names and datatypes are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42af691d",
   "metadata": {
    "id": "42af691d"
   },
   "outputs": [],
   "source": [
    "titanic2 = titanic.drop('deck', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1e379",
   "metadata": {
    "id": "ced1e379"
   },
   "source": [
    "As the schema of the new dataset has been changed, the test will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fecce3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "4fecce3e",
    "outputId": "081f3544-2e55-4cbc-a2f1-58f2daed89f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature pclass converted to Categorical because percentage of unique values 0.003367003367003367 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature sibsp converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature parch converted to Categorical because percentage of unique values 0.007856341189674524 is lower than threshold 0.05611672278338945\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FailedTestError",
     "evalue": "Features do not match. These ones are not present on both datasets ['deck']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:67\u001b[0m, in \u001b[0;36mSameSchemaTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/schemagen.py:334\u001b[0m, in \u001b[0;36mDataSchema.validate\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    333\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeats\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(other\u001b[38;5;241m.\u001b[39mfeats\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures do not match. These ones are not present on both datasets \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# Check feature and data types are the same\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Features do not match. These ones are not present on both datasets ['deck']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSameSchemaTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitanic2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschma_reference\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:69\u001b[0m, in \u001b[0;36mSameSchemaTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema_ref\u001b[38;5;241m.\u001b[39mvalidate(current_schema)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Features do not match. These ones are not present on both datasets ['deck']"
     ]
    }
   ],
   "source": [
    "SameSchemaTest(titanic2, schma_reference).run()  # This will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e3f2d",
   "metadata": {
    "id": "221e3f2d"
   },
   "source": [
    "<a id=\"data_drift\"></a>\n",
    "### Data Drift Test example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5757d",
   "metadata": {
    "id": "77c5757d"
   },
   "source": [
    "Again, for this test, we first need to have an already built Mercury's `DataSchema` object with the schema of the original dataset (e.g. training data). Note it doesn't need to be generated on every test, as it can also be serialized and loaded back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd9c811",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acd9c811",
    "outputId": "4df71d4e-b18f-4da3-82cb-d28d648bd198"
   },
   "outputs": [],
   "source": [
    "schma_reference = DataSchema().generate(titanic).calculate_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73230511",
   "metadata": {
    "id": "73230511"
   },
   "source": [
    "First, run a test with no existing drift. It will pass..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14615b8",
   "metadata": {
    "id": "b14615b8"
   },
   "outputs": [],
   "source": [
    "test = DriftTest(titanic, schma_reference).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2e721",
   "metadata": {
    "id": "fec2e721"
   },
   "source": [
    "We now simulate several types of drift. Let's start with a drift on the `age` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e47269",
   "metadata": {
    "id": "65e47269"
   },
   "outputs": [],
   "source": [
    "titanic2 = titanic.copy()\n",
    "titanic2['age'] *= titanic2['age']  # quadratic relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba61cb59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "ba61cb59",
    "outputId": "a529f457-374d-47d9-af79-491612a2e9a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "hist1 = schma_reference.feats['age'].stats['distribution']\n",
    "hist2 = np.histogram(titanic2.loc[:, 'age'],\n",
    "             range=(schma_reference.feats['age'].stats['min'], schma_reference.feats['age'].stats['max']),\n",
    "             bins=len(schma_reference.feats['age'].stats['distribution'])\n",
    "             )[0] #/ len(titanic2.loc[:, x])\n",
    "\n",
    "\n",
    "ax[0].bar(list(range(0, len(hist1))), hist1)\n",
    "ax[1].bar(list(range(0, len(hist2))), hist2)\n",
    "\n",
    "ax[0].set_title('Original distribution')\n",
    "ax[1].set_title('Drifted distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8983f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "fe8983f2",
    "outputId": "0f167626-4212-4ad3-9fbf-f2bd38a93aa3"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. Drift was detected on the following features: ['age']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDriftTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitanic2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschma_reference\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:255\u001b[0m, in \u001b[0;36mDriftTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_drift_metrics \u001b[38;5;241m=\u001b[39m drift_detector\u001b[38;5;241m.\u001b[39mcalculate_drift()\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_drift_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrift_detected\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. Drift was detected on the following features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrift_detector\u001b[38;5;241m.\u001b[39mget_drifted_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Test categorical feats with Chi2\u001b[39;00m\n\u001b[1;32m    258\u001b[0m featnames \u001b[38;5;241m=\u001b[39m schema_ref\u001b[38;5;241m.\u001b[39mbinary_feats \u001b[38;5;241m+\u001b[39m schema_ref\u001b[38;5;241m.\u001b[39mcategorical_feats\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. Drift was detected on the following features: ['age']"
     ]
    }
   ],
   "source": [
    "DriftTest(titanic2, schma_reference).run()  # This will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4da564",
   "metadata": {
    "id": "8c4da564"
   },
   "source": [
    "Next, let's simulate we lose one of the categories from `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61983a80",
   "metadata": {
    "id": "61983a80"
   },
   "outputs": [],
   "source": [
    "titanic2 = titanic.copy()\n",
    "titanic2['sex'] = 'male'   # We lose one of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ba505b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "34ba505b",
    "outputId": "3fedf406-d6c4-4638-cac8-b2c870431e55"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. Drift was detected on the following features: ['sex']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDriftTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitanic2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschma_reference\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:278\u001b[0m, in \u001b[0;36mDriftTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_drift_metrics \u001b[38;5;241m=\u001b[39m drift_detector\u001b[38;5;241m.\u001b[39mcalculate_drift()\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_drift_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrift_detected\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. Drift was detected on the following features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrift_detector\u001b[38;5;241m.\u001b[39mget_drifted_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. Drift was detected on the following features: ['sex']"
     ]
    }
   ],
   "source": [
    "DriftTest(titanic2, schma_reference).run()  # This will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d1d7f",
   "metadata": {
    "id": "571d1d7f"
   },
   "source": [
    "<a id=\"linear_combinations\"></a>\n",
    "### Linear combinations Test example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333e9f6",
   "metadata": {
    "id": "1333e9f6"
   },
   "source": [
    "This test searches linear combinations between your numerical features (only the continuous ones at the time of writing this tutorial).\n",
    "\n",
    "Let's extract continuous features from the titanic dataset and run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82090552",
   "metadata": {
    "id": "82090552"
   },
   "outputs": [],
   "source": [
    "test_df = titanic.loc[:, schma_reference.continuous_feats].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b6fc537",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "3b6fc537",
    "outputId": "ef160675-4e22-4a69-c15a-0e477aac710b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     fare\n",
       "0  22.0   7.2500\n",
       "1  38.0  71.2833"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7f69e",
   "metadata": {
    "id": "a0b7f69e"
   },
   "source": [
    "As these two features are independent, no linear combinations will be found, so the test will pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6cd86c",
   "metadata": {
    "id": "7d6cd86c"
   },
   "outputs": [],
   "source": [
    "LinearCombinationsTest(test_df).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93560e00",
   "metadata": {
    "id": "93560e00"
   },
   "source": [
    "Let's artificially generate a dataset with a column which is linearly dependent with `age`. This aims to serve as an example when we have a dataset with clear feature dependencies, which should be removed prior to model trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f188ded7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "f188ded7",
    "outputId": "addd7de5-3165-4534-bb7b-dea63b42126f"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. Linear combinations for continuous features were encountered.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombination\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mLinearCombinationsTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:137\u001b[0m, in \u001b[0;36mLinearCombinationsTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     lin_combinations \u001b[38;5;241m=\u001b[39m lin_combs_in_columns(\n\u001b[1;32m    133\u001b[0m         np\u001b[38;5;241m.\u001b[39mmatmul(cont_cols\u001b[38;5;241m.\u001b[39mT, cont_cols)  \u001b[38;5;66;03m# Compress original matrix\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lin_combinations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. Linear combinations for continuous features were encountered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m individually_redundant \u001b[38;5;241m=\u001b[39m CategoryStruct\u001b[38;5;241m.\u001b[39mindividually_redundant(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dataset, current_schema\u001b[38;5;241m.\u001b[39mcategorical_feats)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(individually_redundant) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. Linear combinations for continuous features were encountered."
     ]
    }
   ],
   "source": [
    "test_df['combination'] = test_df['age'] * 2\n",
    "LinearCombinationsTest(test_df).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f6e35c",
   "metadata": {
    "id": "e6f6e35c"
   },
   "source": [
    "<a id=\"label_leaking\"></a>\n",
    "### Label leaking Test example\n",
    "\n",
    "This test seeks for any strong relationship between any of the predictor variables and the target. If found, it fails.\n",
    "\n",
    "Let us load the tips dataset and simulate a nonlinear relationship with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c6ac70",
   "metadata": {
    "id": "02c6ac70"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f278fc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "7f278fc3",
    "outputId": "e9d5f074-9822-428f-a65c-78c3fa7efbd5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/l44dx4nx06bc4wcs81jd6cr00000gq/T/ipykernel_47313/1709824187.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tips.loc[:, feat] = preprocessing.LabelEncoder().fit_transform(tips.loc[:, feat])\n",
      "/var/folders/kd/l44dx4nx06bc4wcs81jd6cr00000gq/T/ipykernel_47313/1709824187.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tips.loc[:, feat] = preprocessing.LabelEncoder().fit_transform(tips.loc[:, feat])\n",
      "/var/folders/kd/l44dx4nx06bc4wcs81jd6cr00000gq/T/ipykernel_47313/1709824187.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tips.loc[:, feat] = preprocessing.LabelEncoder().fit_transform(tips.loc[:, feat])\n",
      "/var/folders/kd/l44dx4nx06bc4wcs81jd6cr00000gq/T/ipykernel_47313/1709824187.py:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tips.loc[:, feat] = preprocessing.LabelEncoder().fit_transform(tips.loc[:, feat])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip  sex  smoker  day  time  size\n",
       "0       16.99  1.01    0       0    2     0     2\n",
       "1       10.34  1.66    1       0    2     0     3\n",
       "2       21.01  3.50    1       0    2     0     3\n",
       "3       23.68  3.31    1       0    2     0     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['sex'] = tips['sex'].astype(str)\n",
    "tips['smoker'] = tips['smoker'].astype(str)\n",
    "tips['day'] = tips['day'].astype(str)\n",
    "tips['time'] = tips['time'].astype(str)\n",
    "\n",
    "for feat in ['sex', 'smoker', 'day', 'time']:\n",
    "    tips.loc[:, feat] = preprocessing.LabelEncoder().fit_transform(tips.loc[:, feat])\n",
    "\n",
    "tips.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a1bbd",
   "metadata": {
    "id": "5e4a1bbd"
   },
   "source": [
    "In this case, `injected` will be the target variable squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "580e69bd",
   "metadata": {
    "id": "580e69bd"
   },
   "outputs": [],
   "source": [
    "tips['injected'] = tips['total_bill'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1678dc",
   "metadata": {
    "id": "ae1678dc"
   },
   "source": [
    "We create and run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13710585",
   "metadata": {
    "id": "13710585"
   },
   "outputs": [],
   "source": [
    "test = LabelLeakingTest(\n",
    "    tips,\n",
    "    label_name='total_bill',\n",
    "    threshold = 0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb5a828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "1bb5a828",
    "outputId": "78fd8846-a8bf-4684-83f0-8d697f62b9f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature day converted to Categorical because percentage of unique values 0.01639344262295082 is lower than threshold 0.20491803278688525\n",
      "  warnings.warn(\n",
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature size converted to Categorical because percentage of unique values 0.02459016393442623 is lower than threshold 0.20491803278688525\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FailedTestError",
     "evalue": "Test failed because high importance features were detected: ['injected']. Check for possible target leaking.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:558\u001b[0m, in \u001b[0;36mLabelLeakingTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m idxs \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfeature_importances[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m][high_importance_feats]\n\u001b[1;32m    557\u001b[0m names \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[idxs]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError((\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed because high importance features were detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck for possible target leaking.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m ))\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed because high importance features were detected: ['injected']. Check for possible target leaking."
     ]
    }
   ],
   "source": [
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353749b8",
   "metadata": {
    "id": "353749b8"
   },
   "source": [
    "Because the test failed, we can take a look at the `importances_` attribute. It is a dictionary with all the predictor features and their \"relationship\" to the target. \n",
    "\n",
    "This \"relationship\" is simply the result of a chosen metric whose best value is $1$ (by default: ROC-AUC for classification and $R^2$ for regression; although you can manually specify other metric via the `metric` parameter). Thus, if any of the features is too close to 1 ($> 1 - threshold$), the test will fail. The threshold can be configured via the `threshold` parameter, so using a higher threshold will require a higher importance on the feature to make the test fail.\n",
    "\n",
    "*Note: Note that the chosen metric doesn't have to be the one you're optimizing. The purpose of this test is only to find strong relationships, so almost any metric will do the job.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b62071d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b62071d",
    "outputId": "3c8f2bda-4799-4791-bdcd-49f56974854c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smoker': 0.007348133957009506,\n",
       " 'sex': 0.020989442787269885,\n",
       " 'day': 0.03343679742214034,\n",
       " 'time': 0.033532057384179303,\n",
       " 'size': 0.3706735216893777,\n",
       " 'tip': 0.511194450488601,\n",
       " 'injected': 0.9749336284220832}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b88dd",
   "metadata": {
    "id": "5b3b88dd"
   },
   "source": [
    "Internally, this test uses a selection method based on tree models. After the test is done, you can inspect the fitted object with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd828b39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd828b39",
    "outputId": "04a082ed-f134-476e-e002-f1296b829618"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': array([2, 1, 3, 4, 5, 0, 6]),\n",
       " 'metrics': [0.007348133957009506,\n",
       "  0.020989442787269885,\n",
       "  0.03343679742214034,\n",
       "  0.033532057384179303,\n",
       "  0.3706735216893777,\n",
       "  0.511194450488601,\n",
       "  0.9749336284220832]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._selector.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8a721",
   "metadata": {
    "id": "a0c8a721"
   },
   "source": [
    "<a id=\"noisy_labels\"></a>\n",
    "### Noisy Labels Test example\n",
    "\n",
    "This test looks at the labels of the dataset and fails if there are a high number of samples where the labels are considered noisy. Noisy labels can happen for several reasons. For example, they can occur due to errors in the labelling process, or because some samples might not belong to just one specific label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce164e",
   "metadata": {
    "id": "61ce164e"
   },
   "source": [
    "<b> Tabular Dataset: Titanic </b>\n",
    "\n",
    "Let's first use the test in the titanic dataset. We will keep only some columns and discard rows with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e5cb43f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9e5cb43f",
    "outputId": "e4c67f9c-f311-4368-f5d2-b8409d941f40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age     fare    who\n",
       "0         0       3    male  22.0   7.2500    man\n",
       "1         1       1  female  38.0  71.2833  woman\n",
       "2         1       3  female  26.0   7.9250  woman\n",
       "3         1       1  female  35.0  53.1000  woman\n",
       "4         0       3    male  35.0   8.0500    man"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = titanic[[\"survived\", \"pclass\", \"sex\", \"age\", \"fare\", \"who\"]].dropna().copy()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ea2dd",
   "metadata": {
    "id": "845ea2dd"
   },
   "source": [
    "Now we create the `NoisyLabelsTest`. \n",
    "\n",
    "We specify the dataset, the label name and a threshold of 0.25, which means that if more than 25% are detected as noisy then the text will fail. \n",
    "\n",
    "We also specify some parameters for the algorithm detecting the noisy labels (internally, it uses the test uses the [cleanlab](https://cleanlab.readthedocs.io/en/latest/) library). In this case, we specify that the algorithm will use a Random Forest to compute the probabilities (if we left the default configuration it uses a Logistic Regression). You can see more configurable parameters in the documentation.\n",
    "\n",
    "Another important point is that the dataset contains string features. In this case, as we do not specify the `preprocessor` argument, then the test will use a `OneHotEncoding` to encode these features. Alternatively, it is possible to pass a `preprocessor` to apply to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6521e4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6521e4d",
    "outputId": "03615810-2028-4d47-f33f-63e1eeef1505"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature pclass converted to Categorical because percentage of unique values 0.004201680672268907 is lower than threshold 0.0700280112044818\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "label_issues_args = dict(\n",
    "    clf=RandomForestClassifier(max_depth=4)\n",
    ")\n",
    "\n",
    "test = NoisyLabelsTest(\n",
    "    train_df,\n",
    "    label_name='survived',\n",
    "    threshold=0.25,\n",
    "    label_issues_args=label_issues_args\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcc372",
   "metadata": {
    "id": "2afcc372"
   },
   "source": [
    "The test has passed. We can also look at the percentage of labels detected as noisy looking at the property `rate_issues_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26ab230a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ab230a",
    "outputId": "d36c2df1-b46d-4a37-b4d3-cee10cbf21eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08683473389355742"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rate_issues_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c9271",
   "metadata": {
    "id": "2a2c9271"
   },
   "source": [
    "Now, let's introduce noise in the labels and see if the test keeps passing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a3942f",
   "metadata": {
    "id": "49a3942f"
   },
   "outputs": [],
   "source": [
    "train_df[\"survived\"] = np.random.choice([0,1], replace=True, size=len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a34f248f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "a34f248f",
    "outputId": "de1ae583-65b9-4c2b-fb6a-86e72702a50e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e055518/Library/Python/3.9/lib/python/site-packages/mercury/dataschema/feature.py:306: RuntimeWarning: INTEGER feature pclass converted to Categorical because percentage of unique values 0.004201680672268907 is lower than threshold 0.0700280112044818\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. High level of noise detected in labels. Percentage of labels with noise: 0.4803921568627451",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m label_issues_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      2\u001b[0m     clf\u001b[38;5;241m=\u001b[39mRandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m test \u001b[38;5;241m=\u001b[39m NoisyLabelsTest(\n\u001b[1;32m      6\u001b[0m     train_df,\n\u001b[1;32m      7\u001b[0m     label_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurvived\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m      9\u001b[0m     label_issues_args\u001b[38;5;241m=\u001b[39mlabel_issues_args\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:798\u001b[0m, in \u001b[0;36mNoisyLabelsTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# If percentage of issues is higher than threshold, throw exception\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_issues_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold:\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. High level of noise detected in labels. Percentage of labels with noise: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_issues_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    800\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. High level of noise detected in labels. Percentage of labels with noise: 0.4803921568627451"
     ]
    }
   ],
   "source": [
    "label_issues_args = dict(\n",
    "    clf=RandomForestClassifier(max_depth=4)\n",
    ")\n",
    "\n",
    "test = NoisyLabelsTest(\n",
    "    train_df,\n",
    "    label_name='survived',\n",
    "    threshold=0.25,\n",
    "    label_issues_args=label_issues_args\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16450d43",
   "metadata": {
    "id": "16450d43"
   },
   "source": [
    "We see that now the test fails since the percentage of labels detected with noise is higher than the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2737803",
   "metadata": {
    "id": "b2737803"
   },
   "source": [
    "<b> Text Dataset: Banking Intents </b>\n",
    "\n",
    "The test can also be used with text datasets.\n",
    "\n",
    "We will use it with the banking intents dataset, which contains short customer queries classified under 77 possible labels. This dataset was used in [[1]](#[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "rH6UPPfkU-x2",
   "metadata": {
    "id": "rH6UPPfkU-x2"
   },
   "outputs": [],
   "source": [
    "path_dataset = \"./data/bankintents/\"\n",
    "train_df = pd.read_csv(path_dataset + \"train.csv\")\n",
    "test_df = pd.read_csv(path_dataset + \"test.csv\")\n",
    "categories_df = pd.read_json(path_dataset + \"categories.json\")\n",
    "train_df = train_df.sample(frac=1, random_state=342)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba5a229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fba5a229",
    "outputId": "6d5c1b6f-eacb-4598-8830-64d612e638f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>how do i set up my apple pay watch to connect ...</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>train</td>\n",
       "      <td>74</td>\n",
       "      <td>9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>Why isn't my balance updating after depositing...</td>\n",
       "      <td>balance_not_updated_after_cheque_or_cash_deposit</td>\n",
       "      <td>train</td>\n",
       "      <td>26</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>How do you decide what your exchange rates are?</td>\n",
       "      <td>exchange_rate</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>I see a direct debit transaction that I didn't...</td>\n",
       "      <td>direct_debit_payment_not_recognised</td>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>4669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>How can I create another card linked to this a...</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>train</td>\n",
       "      <td>60</td>\n",
       "      <td>7815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "9695  how do i set up my apple pay watch to connect ...   \n",
       "3369  Why isn't my balance updating after depositing...   \n",
       "377     How do you decide what your exchange rates are?   \n",
       "4669  I see a direct debit transaction that I didn't...   \n",
       "7815  How can I create another card linked to this a...   \n",
       "\n",
       "                                              category    set  category_id  \\\n",
       "9695                           apple_pay_or_google_pay  train           74   \n",
       "3369  balance_not_updated_after_cheque_or_cash_deposit  train           26   \n",
       "377                                      exchange_rate  train            2   \n",
       "4669               direct_debit_payment_not_recognised  train           37   \n",
       "7815                                getting_spare_card  train           60   \n",
       "\n",
       "        id  \n",
       "9695  9695  \n",
       "3369  3369  \n",
       "377    377  \n",
       "4669  4669  \n",
       "7815  7815  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2df4c",
   "metadata": {
    "id": "70e2df4c"
   },
   "source": [
    "When using a text dataset we need to specify the `text_col` parameter, which is the column containing the text in the dataframe. If we do not specify a preprocessor, a `CountVectorizer` is created internally to convert the text to a format valid for ML models. Alternatively, you can specify your own text preprocessor as we show in a later example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03f1fff2",
   "metadata": {
    "id": "03f1fff2"
   },
   "outputs": [],
   "source": [
    "label_issues_args = dict(\n",
    "    clf=RandomForestClassifier()\n",
    ")\n",
    "\n",
    "test = NoisyLabelsTest(\n",
    "    train_df[[\"text\", \"category_id\"]],\n",
    "    label_name='category_id',\n",
    "    text_col=\"text\",\n",
    "    threshold=0.25,\n",
    "    label_issues_args=label_issues_args\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b4d1e",
   "metadata": {
    "id": "b39b4d1e"
   },
   "source": [
    "We can see that the test has passed. We can see the percentage of noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c2b1e7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c2b1e7f",
    "outputId": "a9c6689a-5165-455f-f9d3-6c80e3cf123a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030290912726182145"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rate_issues_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3508f5",
   "metadata": {
    "id": "6a3508f5"
   },
   "source": [
    "As we mentioned above, we can specify the text preprocessor instead of using one by default. We will use now a `TfidfVectorizer`. We also change the labels to make them noisy and see if the test is able to capture it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8395a774",
   "metadata": {
    "id": "8395a774"
   },
   "outputs": [],
   "source": [
    "train_df[\"category_id\"] = np.random.choice(train_df[\"category_id\"].unique(), replace=True, size=len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17f02b91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "17f02b91",
    "outputId": "9ef480dd-ea80-4035-8d39-c56a886c7026"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. High level of noise detected in labels. Percentage of labels with noise: 0.9792062381285614",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m label_issues_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      5\u001b[0m     clf\u001b[38;5;241m=\u001b[39mRandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m),\n\u001b[1;32m      6\u001b[0m     sorted_index_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob_given_label\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m test \u001b[38;5;241m=\u001b[39m NoisyLabelsTest(\n\u001b[1;32m     10\u001b[0m     train_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     11\u001b[0m     label_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     label_issues_args\u001b[38;5;241m=\u001b[39mlabel_issues_args\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:798\u001b[0m, in \u001b[0;36mNoisyLabelsTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# If percentage of issues is higher than threshold, throw exception\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_issues_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold:\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. High level of noise detected in labels. Percentage of labels with noise: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_issues_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    800\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. High level of noise detected in labels. Percentage of labels with noise: 0.9792062381285614"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=8000, stop_words='english')\n",
    "\n",
    "label_issues_args = dict(\n",
    "    clf=RandomForestClassifier(max_depth=6),\n",
    "    sorted_index_method='prob_given_label',\n",
    ")\n",
    "\n",
    "test = NoisyLabelsTest(\n",
    "    train_df[[\"text\", \"category_id\"]],\n",
    "    label_name='category_id',\n",
    "    text_col=\"text\",\n",
    "    preprocessor=tfidf,\n",
    "    threshold=0.25,\n",
    "    label_issues_args=label_issues_args\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f8a83",
   "metadata": {
    "id": "ee5f8a83"
   },
   "source": [
    "We see that now the test has failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0136d",
   "metadata": {
    "id": "b5f0136d"
   },
   "source": [
    "<a id=\"cohort_performance\"></a>\n",
    "### Cohort Performance Test\n",
    "\n",
    "The Cohort Performance Test looks if some metric performs poorly for some group of your data in comparison with other groups. The user can specify an evaluation function that returns the metric to check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280f43d",
   "metadata": {
    "id": "d280f43d"
   },
   "source": [
    "\n",
    "\n",
    "We will use the default credit card Dataset from the UCI machine learning repository. The dataset was used in [[2]](#[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f837137",
   "metadata": {
    "id": "6f837137"
   },
   "outputs": [],
   "source": [
    "path_dataset = \"./data/credit/\"\n",
    "uci_credit = pd.read_csv(path_dataset + \"UCI_Credit_card.csv\")\n",
    "\n",
    "uci_credit[\"SEX\"] = uci_credit[\"SEX\"].astype(str)\n",
    "uci_credit[\"EDUCATION\"] = uci_credit[\"EDUCATION\"].astype(str)\n",
    "uci_credit[\"MARRIAGE\"] = uci_credit[\"MARRIAGE\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbb0ff",
   "metadata": {
    "id": "eabbb0ff"
   },
   "source": [
    "Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb5972db",
   "metadata": {
    "id": "eb5972db"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(uci_credit, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fcdfdb",
   "metadata": {
    "id": "77fcdfdb"
   },
   "source": [
    "Now we create a pipeline with the preprocessing of the features and a Logistic Regression model. Note that for illustration purposes we use features that we shouldn't use like the gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8eb109c3",
   "metadata": {
    "id": "8eb109c3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "label_col = \"default.payment.next.month\"\n",
    "\n",
    "pay_feats = [c for c in df_train.columns if \"PAY_\" in c]\n",
    "bill_feats = [c for c in df_train.columns if \"BILL_\" in c]\n",
    "numeric_features = ['LIMIT_BAL', 'AGE'] + pay_feats + bill_feats\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = [\n",
    "    'SEX', 'EDUCATION', 'MARRIAGE'\n",
    "]\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor), \n",
    "        (\"classifier\", LogisticRegression(solver='newton-cg', class_weight='balanced'))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cd93d",
   "metadata": {
    "id": "af5cd93d"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbae9f3f",
   "metadata": {
    "id": "cbae9f3f"
   },
   "outputs": [],
   "source": [
    "X_train = df_train[numeric_features + categorical_features]\n",
    "y_train = df_train[label_col]\n",
    "X_test = df_test[numeric_features + categorical_features]\n",
    "y_test = df_test[label_col]\n",
    "\n",
    "pipeline = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035d914",
   "metadata": {
    "id": "9035d914"
   },
   "source": [
    "Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "520d0a6f",
   "metadata": {
    "id": "520d0a6f"
   },
   "outputs": [],
   "source": [
    "df_test = df_test.copy()\n",
    "df_test[\"class_pred\"] = pipeline.predict(X_test)\n",
    "\n",
    "probs = pipeline.predict_proba(X_test)\n",
    "col_probs = []\n",
    "for i in range(probs.shape[1]):\n",
    "    df_test[\"prob_\" + str(i)] = probs[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e57e96",
   "metadata": {
    "id": "28e57e96"
   },
   "source": [
    "Now, let's create the test. It needs an evaluation function for the metric that the test will check. In this case, we will just measure the AUC. \n",
    "\n",
    "The `CohortPerformanceTest` has two arguments to control how the metrics are compared with the threshold. \n",
    "\n",
    "- If the argument `compare_max_diff` is True (default value) then the threshold is compared between the group with the highest value for the metric and the group with the lowest value for the metric. If the argument `compare_max_diff` is set to False then each group is compared against the mean of the metric for the whole dataset. \n",
    "\n",
    "- The second argument is `threshold_is_percentage` controls if the threshold is considered a percentage or an absolute value of the metric. If `threshold_is_percentage=True` (default value) then the threshold is considered as a percentage and the comparison is made by checking the percentage of the differences. If `threshold_is_percentage=False` then the threshold is considered an absolute value, and the differences as absolute value are compared.\n",
    "\n",
    "In this case, we look at AUC of the groups of the variable 'SEX'. We set a threshold of 0.1, and we let `compare_max_diff` and `threshold_is_percentage` with the default values (both True). That means that the test will fail if the highest AUC in the group SEX is 10% or higher than the lowest AUC in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f258a395",
   "metadata": {
    "id": "f258a395"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval_auc(df):\n",
    "    return roc_auc_score(df[label_col], df[\"prob_1\"])\n",
    "\n",
    "test1 = CohortPerformanceTest(\n",
    "    base_dataset=df_test, group_col=\"SEX\", eval_fn = eval_auc, threshold = 0.1\n",
    ")\n",
    "test1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AUaGU5EEyvwA",
   "metadata": {
    "id": "AUaGU5EEyvwA"
   },
   "source": [
    "We see that the test passes. We can see some details calling the `info()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mdfH5hK8wJJa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdfH5hK8wJJa",
    "outputId": "582751a8-25e5-4882-dd89-40c29b7f7f44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_by_group': SEX\n",
       " 1    0.742573\n",
       " 2    0.708878\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZzHcTwYt0QsM",
   "metadata": {
    "id": "ZzHcTwYt0QsM"
   },
   "source": [
    "We see that group 1 has a higher AUC, but not enough to make the test fail with the settings we set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeed142",
   "metadata": {
    "id": "0eeed142"
   },
   "source": [
    "Let's try different options now. We set `compare_max_diff` to False to compare the metrics with the mean of the dataset. We also set `threshold_is_percentage` to False to compare absolute values instead of percentage. We will use a different metric, the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "071dd53a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "071dd53a",
    "outputId": "43b54339-331f-4430-f907-27cbb601cba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean metric:  0.6858333333333333\n",
      "metric by group:  SEX\n",
      "1    0.638169\n",
      "2    0.715798\n",
      "dtype: float64\n",
      "diff:  SEX\n",
      "1    0.047664\n",
      "2   -0.029965\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def eval_accuracy(df):\n",
    "    return accuracy_score(df[label_col], df[\"class_pred\"])\n",
    "\n",
    "test2 = CohortPerformanceTest(\n",
    "    base_dataset=df_test, group_col=\"SEX\", eval_fn = eval_accuracy, \n",
    "    threshold = 0.05, compare_max_diff=False, threshold_is_percentage=False\n",
    ")\n",
    "test2.run()\n",
    "\n",
    "print(\"mean metric: \", test2.mean_metric)\n",
    "print(\"metric by group: \", test2.metric_by_group)\n",
    "print(\"diff: \", test2.diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09883085",
   "metadata": {
    "id": "09883085"
   },
   "source": [
    "We see that the test passed again. We also see that we can check the computed metrics. The average of the metric is available in the attribute `mean_metric` (only computed when parameter `compare_max_diff=False`). The metrics of each group are available in the attribute `metric_by_group`, and the computed difference are available in attribute `diff`\n",
    "\n",
    "Let's do a finally test. We will check the mean prediction of the probability of default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e88e567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "9e88e567",
    "outputId": "7990a984-95cf-40eb-b1d1-a4b71e8cf8a7"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed because max difference 0.109 is higher than threshold 0.05 for groups in SEX.  Group 1 has a metric of 0.483 and Group 2 has a metric of 0.436",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m test3 \u001b[38;5;241m=\u001b[39m CohortPerformanceTest(\n\u001b[1;32m      5\u001b[0m     base_dataset\u001b[38;5;241m=\u001b[39mdf_test, group_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEX\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_fn \u001b[38;5;241m=\u001b[39m eval_mean_prediction, threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m      6\u001b[0m     threshold_is_percentage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtest3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:916\u001b[0m, in \u001b[0;36mCohortPerformanceTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_by_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_col)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_fn(x))\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompare_max_diff:\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compare_max_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compare_diff_with_mean()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:883\u001b[0m, in \u001b[0;36mCohortPerformanceTest._compare_max_diff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff \u001b[38;5;241m=\u001b[39m max_value \u001b[38;5;241m-\u001b[39m min_value\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold:\n\u001b[0;32m--> 883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError((\n\u001b[1;32m    884\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed because max difference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is higher than threshold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for groups in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_by_group\u001b[38;5;241m.\u001b[39midxmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has a metric of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(max_value,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and Group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_by_group\u001b[38;5;241m.\u001b[39midxmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has a metric of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(min_value,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m     ))\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed because max difference 0.109 is higher than threshold 0.05 for groups in SEX.  Group 1 has a metric of 0.483 and Group 2 has a metric of 0.436"
     ]
    }
   ],
   "source": [
    "def eval_mean_prediction(df):\n",
    "    return df[\"prob_1\"].mean()\n",
    "\n",
    "test3 = CohortPerformanceTest(\n",
    "    base_dataset=df_test, group_col=\"SEX\", eval_fn = eval_mean_prediction, threshold = 0.05,\n",
    "    threshold_is_percentage=True\n",
    ")\n",
    "test3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc128f",
   "metadata": {
    "id": "5bcc128f"
   },
   "source": [
    "Now the test has failed, the average of the probability predictions for the group 1 is 11% higher than for group 2, which is higher than the 5% that we specified as threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f0436",
   "metadata": {
    "id": "f78f0436"
   },
   "source": [
    "<a id=\"model_reproducibility\"></a>\n",
    "### Model Reproducibility Test\n",
    "\n",
    "We use now the ModelReproducibilityTest, which checks if training a model is reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8feaea",
   "metadata": {
    "id": "6d8feaea"
   },
   "source": [
    "Let's start obtaining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd648e2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fd648e2f",
    "outputId": "fe1e3cb2-232c-429c-c4a1-7944ec1237d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/l44dx4nx06bc4wcs81jd6cr00000gq/T/ipykernel_47313/1501827911.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  titanic2.loc[:, 'sex'] = preprocessing.LabelEncoder().fit_transform(titanic2.loc[:, 'sex'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex   age     fare\n",
       "0         0       3    1  22.0   7.2500\n",
       "1         1       1    0  38.0  71.2833\n",
       "2         1       3    0  26.0   7.9250\n",
       "3         1       1    0  35.0  53.1000\n",
       "4         0       3    1  35.0   8.0500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "titanic2 = titanic[[\"survived\", \"pclass\", \"sex\", \"age\", \"fare\"]].dropna().copy()\n",
    "titanic2.loc[:, 'sex'] = preprocessing.LabelEncoder().fit_transform(titanic2.loc[:, 'sex'])\n",
    "titanic2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54144366",
   "metadata": {
    "id": "54144366"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(titanic2, test_size=0.2, random_state=0)\n",
    "features = [\"pclass\", \"sex\", \"age\", \"fare\"]\n",
    "label_col = \"survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fba25",
   "metadata": {
    "id": "bb9fba25"
   },
   "source": [
    "Let's first test a <b>reproducible model</b>: a Random Forest with the random state set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "852ce0d4",
   "metadata": {
    "id": "852ce0d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=2222)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5374bb9",
   "metadata": {
    "id": "f5374bb9"
   },
   "source": [
    "We need to specify a function to train the model. Also, an evaluation function that returns a metric and a function that returns the predictions (only one of these last two functions is mandatory for this test, but at least one needs to be specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4646f21f",
   "metadata": {
    "id": "4646f21f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def train_model(model, X, y, train_params=None):\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "    \n",
    "def eval_model(model, X, y, eval_params=None):\n",
    "    y_pred = model.predict(X)\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "def get_predictions(model, X, pred_params=None):\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01214e",
   "metadata": {
    "id": "5a01214e"
   },
   "source": [
    "Now, let's execute the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fa0fec8",
   "metadata": {
    "id": "9fa0fec8"
   },
   "outputs": [],
   "source": [
    "from mercury.robust.model_tests import ModelReproducibilityTest\n",
    "test = ModelReproducibilityTest(\n",
    "    model = model,\n",
    "    train_dataset = df_train[features + [label_col]],\n",
    "    target = label_col,\n",
    "    train_fn = train_model,\n",
    "    train_params = None,\n",
    "    eval_fn = eval_model,\n",
    "    eval_params = None,\n",
    "    threshold_eval = 0,\n",
    "    predict_fn = get_predictions,\n",
    "    predict_params = None,\n",
    "    threshold_yhat = 0,\n",
    "    test_dataset = df_test[features + [label_col]]\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1f242",
   "metadata": {
    "id": "06a1f242"
   },
   "source": [
    "The test passes\n",
    "Now let's try a non-reproducible model: another Random Forest but now without setting the random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c62ce633",
   "metadata": {
    "id": "c62ce633"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6039c6ad",
   "metadata": {
    "id": "6039c6ad"
   },
   "source": [
    "We can use the same training function, evaluation function, and get predictions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "427bacbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "427bacbc",
    "outputId": "1e0e0813-ee30-400c-f1f1-4efd65da7be7"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Eval metric different in test dataset when training two times (0.8112 vs 0.7972). The max difference allowed is 0 The model is not reproducible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m ModelReproducibilityTest(\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m      3\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m df_train[features \u001b[38;5;241m+\u001b[39m [label_col]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     test_dataset \u001b[38;5;241m=\u001b[39m df_test[features \u001b[38;5;241m+\u001b[39m [label_col]]\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/model_tests.py:190\u001b[0m, in \u001b[0;36mModelReproducibilityTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# Check evaluation on test\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_diff_in_eval(model_1, model_2, X_test, y_test):\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval metric different in test dataset when training two times (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_1,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_2,\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max difference allowed is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_eval, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is not reproducible.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Check evaluation on train\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_diff_in_predictions(model_1, model_2, X_train):\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Eval metric different in test dataset when training two times (0.8112 vs 0.7972). The max difference allowed is 0 The model is not reproducible."
     ]
    }
   ],
   "source": [
    "test = ModelReproducibilityTest(\n",
    "    model = model,\n",
    "    train_dataset = df_train[features + [label_col]],\n",
    "    target = label_col,\n",
    "    train_fn = train_model,\n",
    "    train_params = None,\n",
    "    eval_fn = eval_model,\n",
    "    threshold_eval = 0,\n",
    "    predict_fn = get_predictions,\n",
    "    threshold_yhat = 0,\n",
    "    test_dataset = df_test[features + [label_col]]\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c12bf",
   "metadata": {
    "id": "c29c12bf"
   },
   "source": [
    "We see that now the test fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fb4b9",
   "metadata": {
    "id": "418fb4b9"
   },
   "source": [
    "<a id=\"model_simplicity\"></a>\n",
    "### Model Simplicity Test\n",
    "\n",
    "We now use the `ModelSimplicityTest`. This test looks if a trained model has a simple baseline which trained in the same dataset gives better or similar performance on a test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bd8fe",
   "metadata": {
    "id": "747bd8fe"
   },
   "source": [
    "We will use again the default credit card Dataset from the UCI machine learning repository [[2]](#[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2f3a8bc",
   "metadata": {
    "id": "c2f3a8bc"
   },
   "outputs": [],
   "source": [
    "path_dataset = \"./data/credit/\"\n",
    "uci_credit = pd.read_csv(path_dataset + \"UCI_Credit_card.csv\")\n",
    "\n",
    "uci_credit[\"SEX\"] = uci_credit[\"SEX\"].astype(str)\n",
    "uci_credit[\"EDUCATION\"] = uci_credit[\"EDUCATION\"].astype(str)\n",
    "uci_credit[\"MARRIAGE\"] = uci_credit[\"MARRIAGE\"].astype(str)\n",
    "uci_credit = uci_credit.drop('ID', axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(uci_credit, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "tVwtGoxE5Thb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "tVwtGoxE5Thb",
    "outputId": "769de034-6248-4026-d14d-434f8be651b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL SEX EDUCATION MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  \\\n",
       "0    20000.0   2         2        1   24      2      2     -1     -1     -2   \n",
       "1   120000.0   2         2        2   26     -1      2      0      0      0   \n",
       "2    90000.0   2         2        2   34      0      0      0      0      0   \n",
       "3    50000.0   2         2        1   37      0      0      0      0      0   \n",
       "4    50000.0   1         2        1   57     -1      0     -1      0      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be2dcff7",
   "metadata": {
    "id": "be2dcff7"
   },
   "outputs": [],
   "source": [
    "pay_feats = [c for c in df_train.columns if \"PAY_\" in c]\n",
    "bill_feats = [c for c in df_train.columns if \"BILL_\" in c]\n",
    "num_feats = ['LIMIT_BAL', 'AGE'] + pay_feats + bill_feats\n",
    "\n",
    "cat_feats = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "label_col = \"default.payment.next.month\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7a0c1",
   "metadata": {
    "id": "f7c7a0c1"
   },
   "source": [
    "<b> Train model  </b>\n",
    "\n",
    "We train a model for this dataset. We train a complex Random Forest with 100 estimators and a max_depth of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa818a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aa818a8",
    "outputId": "0b63ccfd-bd5f-42f7-bfdd-1fb476814643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 23)\n",
      "(24000,)\n",
      "(6000, 23)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[num_feats + cat_feats]\n",
    "y_train = df_train[label_col]\n",
    "X_test = df_test[num_feats + cat_feats]\n",
    "y_test = df_test[label_col]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88bb07f6",
   "metadata": {
    "id": "88bb07f6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def create_model(num_feats=None, cat_feats=None):\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, num_feats),\n",
    "            (\"cat\", categorical_transformer, cat_feats),\n",
    "        ], remainder='drop'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), \n",
    "               (\"classifier\", RandomForestClassifier(\n",
    "                   n_estimators=100, max_depth=30, class_weight=\"balanced\", random_state=2000))\n",
    "              ]\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "model = create_model(num_feats, cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95a3358c",
   "metadata": {
    "id": "95a3358c"
   },
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:, [f for f in df_train.columns if f != label_col]]\n",
    "y_train = df_train.loc[:, label_col]\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61933ec",
   "metadata": {
    "id": "f61933ec"
   },
   "source": [
    "<b> Create Test </b>\n",
    "\n",
    "Let's now create the test. If we do not specify a baseline, then a LogisticRegression is considered in case of classification tasks and LinearRegression in case of regression tasks.\n",
    "\n",
    "By default, the accuracy score is used as a metric to compare your model with the baseline. In this case, as we have class imbalance, we will use the `roc_auc_score`.\n",
    "\n",
    "The `threshold=0.02` is used to compare the baseline with our model. As example, suppose that our model achieves an AUC of 0.65. With a threshold of 0.02, that means that if the baseline obtains an AUC of 0.63 or better then the test will fail, since is considered that a simpler model can achieve very similar or better performance.\n",
    "\n",
    "You can check further options of this test in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfbcb327",
   "metadata": {
    "id": "bfbcb327"
   },
   "outputs": [],
   "source": [
    "from mercury.robust.model_tests import ModelSimplicityChecker\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# We want to fix the type of this features so the internal DataSchema don't run type\n",
    "# inference on them.\n",
    "custom_feature_map ={\n",
    "    'PAY_0': FeatType.CONTINUOUS,\n",
    "    'PAY_2': FeatType.CONTINUOUS,\n",
    "    'PAY_3': FeatType.CONTINUOUS,\n",
    "    'PAY_4': FeatType.CONTINUOUS,\n",
    "    'PAY_5': FeatType.CONTINUOUS,\n",
    "    'PAY_6': FeatType.CONTINUOUS,\n",
    "}\n",
    "\n",
    "test = ModelSimplicityChecker(\n",
    "    model = model,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    threshold=0.02,\n",
    "    eval_fn=roc_auc_score,\n",
    "    schema_custom_feature_map = custom_feature_map,\n",
    "    baseline_model=LogisticRegression(solver='newton-cg')\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d785461",
   "metadata": {
    "id": "4d785461"
   },
   "source": [
    "We see that the test has passed, meaning that the baseline used hasn't obtained a better performance. We can check what was the performance of each method by calling the method `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cfdfa5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cfdfa5e",
    "outputId": "1739b2cc-b798-4cf5-c80b-3b1250e3b7d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_model': 0.6493437234160974,\n",
       " 'metric_baseline_model': 0.610456817290953}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725be8ff",
   "metadata": {
    "id": "725be8ff"
   },
   "source": [
    "We can see that the Random Forest is a little bit better and the test passes. We can try to pass the `baseline_model` but this time passing a `LogisticRegression` with `class_weight=\"balanced\"` in order to deal with the class imbalance. We will also increase the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25a67db4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "25a67db4",
    "outputId": "1039b095-cddf-49db-e9c9-0ce09de940fd"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "a LogisticRegression(class_weight='balanced', solver='newton-cg') baseline model gives an evaluation metric of 0.6698 while the original model gives an evaluation metric of 0.6493. The difference is lower than the threshold 0.02",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m ModelSimplicityChecker(\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m      5\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m X_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     schema_custom_feature_map \u001b[38;5;241m=\u001b[39m custom_feature_map\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/model_tests.py:432\u001b[0m, in \u001b[0;36mModelSimplicityChecker.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Compare difference\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_model \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_baseline_model:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124ma \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m baseline model gives an evaluation metric of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_baseline_model, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m while \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mthe original model gives an evaluation metric of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_model, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. The difference is lower than \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mthe threshold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    436\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: a LogisticRegression(class_weight='balanced', solver='newton-cg') baseline model gives an evaluation metric of 0.6698 while the original model gives an evaluation metric of 0.6493. The difference is lower than the threshold 0.02"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "test = ModelSimplicityChecker(\n",
    "    model = model,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    threshold=0.02,\n",
    "    eval_fn=roc_auc_score,\n",
    "    baseline_model=LogisticRegression(solver='newton-cg', class_weight=\"balanced\"),\n",
    "    schema_custom_feature_map = custom_feature_map\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fpJYu1ck6cxY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpJYu1ck6cxY",
    "outputId": "58a794b8-e1fe-4738-a045-6fd77400fd0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_model': 0.6493437234160974,\n",
       " 'metric_baseline_model': 0.6697727020483161}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccffb573",
   "metadata": {
    "id": "ccffb573"
   },
   "source": [
    "We see now that the LogisticRegression baseline model has better performance to the RandomForest and the test fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e2ae5",
   "metadata": {
    "id": "381e2ae5"
   },
   "source": [
    "<a id=\"drift_resistance\"></a>\n",
    "### Drift Resistance Test\n",
    "\n",
    "The `DriftPredictionsResistanceTest` and `DriftMetricResistanceTest` can help you to check how your model is resistance to drift. While the former looks how predictions are affected by drift, the latter looks how a performance metric like the accuracy can be affected. Let's load a dataset, train a couple of models, and expose more details about each test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "765ff96b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "765ff96b",
    "outputId": "73fa8588-1920-4f79-ddb5-efaa52b87e4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['sex'] = tips['sex'].astype(str)\n",
    "tips['smoker'] = tips['smoker'].astype(str)\n",
    "tips['day'] = tips['day'].astype(str)\n",
    "tips['time'] = tips['time'].astype(str)\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "039dd917",
   "metadata": {
    "id": "039dd917"
   },
   "outputs": [],
   "source": [
    "num_feats = ['total_bill']\n",
    "cat_feats = ['sex', 'day', 'time']\n",
    "target = 'tip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6962ca",
   "metadata": {
    "id": "8f6962ca"
   },
   "source": [
    "Let's create a function to create a pipeline for a regression model. We can specifiy between a linear regression or a random forest depending on which value we specify in the parameter `model_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0705e1d8",
   "metadata": {
    "id": "0705e1d8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def create_regression_pipeline(num_feats=None, cat_feats=None, random_state=None, model_type=\"rf\"):\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, num_feats),\n",
    "            (\"cat\", categorical_transformer, cat_feats),\n",
    "        ], remainder='drop'\n",
    "    )\n",
    "    \n",
    "    if model_type == \"rf\":\n",
    "        model =RandomForestRegressor(random_state=random_state)\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "        \n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)]\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60912e0",
   "metadata": {
    "id": "c60912e0"
   },
   "source": [
    "Train Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56a07e26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56a07e26",
    "outputId": "7bead0ab-f93d-4d33-debf-63c33c14fd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7376075819672131\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr = create_regression_pipeline(num_feats=num_feats, cat_feats=cat_feats, model_type=\"lr\")\n",
    "pipeline_lr = pipeline_lr.fit(tips[cat_feats + num_feats], tips[target])\n",
    "y_hat_test_lr = pipeline_lr.predict(tips[cat_feats + num_feats])\n",
    "print(mean_absolute_error(tips[target], y_hat_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc767c5",
   "metadata": {
    "id": "fbc767c5"
   },
   "source": [
    "Train Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42b73928",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42b73928",
    "outputId": "83b8954e-5e5f-4b5a-efbc-b6002a109a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3062412568306011\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = create_regression_pipeline(num_feats=num_feats, cat_feats=cat_feats, model_type=\"rf\")\n",
    "pipeline_rf = pipeline_rf.fit(tips[cat_feats + num_feats], tips[target])\n",
    "y_hat_test_rf = pipeline_rf.predict(tips[cat_feats + num_feats])\n",
    "print(mean_absolute_error(tips[target], y_hat_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7e82b",
   "metadata": {
    "id": "e7e7e82b"
   },
   "source": [
    "<b> Metric Drift Resistance </b>\n",
    "\n",
    "The `DriftMetricResistanceTest` looks if when applying drift to a dataset a metric is affected more than a `tolerance`. For example, in the regression case, it looks (by default) if the mean absolute error diverges more than the specified `tolerance`. We can specify our own performance metric by passing a function in `eval` paramater. In that case, the interface of the function must be `eval_fn(y_true, y_hat)`.\n",
    "\n",
    "The drift that is applied to the dataset is controlled by the `drift_type` and `drift_args` arguments. In the following example, we introduce outliers in the dataset by setting the value `1e5` to half of the points of the dataset.\n",
    "\n",
    "Let's first execute it for the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cecd373",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "8cecd373",
    "outputId": "394be029-217d-4ce3-8cd7-bc8b1abca222"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. The metric of drifted dataset has changed above tolerance = 5.000 (diff = 5271.213)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m drift_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_bill\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod_params\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproportion_outliers\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m}\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m test \u001b[38;5;241m=\u001b[39m DriftMetricResistanceTest(\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m pipeline_lr, \n\u001b[1;32m     10\u001b[0m     X \u001b[38;5;241m=\u001b[39m tips[cat_feats \u001b[38;5;241m+\u001b[39m num_feats], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/model_tests.py:660\u001b[0m, in \u001b[0;36mDriftMetricResistanceTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_performance_degradation(drifted_Y)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_diff \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance:\n\u001b[0;32m--> 660\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. The metric of drifted dataset has changed above tolerance = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m (diff = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_diff)\n\u001b[1;32m    663\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. The metric of drifted dataset has changed above tolerance = 5.000 (diff = 5271.213)"
     ]
    }
   ],
   "source": [
    "from mercury.robust.model_tests import DriftMetricResistanceTest\n",
    "\n",
    "drift_args = {\n",
    "    'cols' : ['total_bill'], \n",
    "    'method' : 'value',\n",
    "    'method_params': {'value': 1e5, 'proportion_outliers': 0.5}\n",
    "}\n",
    "test = DriftMetricResistanceTest(\n",
    "    model = pipeline_lr, \n",
    "    X = tips[cat_feats + num_feats], \n",
    "    Y = tips[\"tip\"].values,\n",
    "    drift_type = 'outliers_drift', \n",
    "    drift_args = drift_args,\n",
    "    tolerance = 5\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44d0dc",
   "metadata": {
    "id": "6d44d0dc"
   },
   "source": [
    "We see that the test fails. The mean squared absolute changes a lot ! We can check this info by calling the `info()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed121302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed121302",
    "outputId": "af86a976-0bb3-4496-8b87-6292c9231a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_no_drifted': 0.7376075819672131,\n",
       " 'metric_drifted': 5271.950660860655,\n",
       " 'metric_diff': 5271.213053278688}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e6ac4",
   "metadata": {
    "id": "ef2e6ac4"
   },
   "source": [
    "Now, let's try with the Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "870edc5c",
   "metadata": {
    "id": "870edc5c"
   },
   "outputs": [],
   "source": [
    "drift_args = {\n",
    "    'cols' : ['total_bill'], \n",
    "    'method' : 'value',\n",
    "    'method_params': {'value': 1e5}\n",
    "}\n",
    "test = DriftMetricResistanceTest(\n",
    "    model = pipeline_rf, \n",
    "    X = tips[cat_feats + num_feats], \n",
    "    drift_type = 'outliers_drift', \n",
    "    drift_args = drift_args,\n",
    "    Y=tips[\"tip\"].values,\n",
    "    tolerance = 5\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb14d668",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb14d668",
    "outputId": "3c948791-afee-4aef-9cb2-b263a66c5a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_no_drifted': 0.3062412568306011,\n",
       " 'metric_drifted': 3.085671584699454,\n",
       " 'metric_diff': 2.7794303278688526}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc97b5b",
   "metadata": {
    "id": "ccc97b5b"
   },
   "source": [
    "We see that now the test passes according to the tolerance specified. As expected, the Random Forest model is less afected by the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910bbcef",
   "metadata": {
    "id": "910bbcef"
   },
   "source": [
    "<b> Prediction Drift Resitance </b>\n",
    "\n",
    "Let's try now the `DriftPredictionsResistanceTest`, which looks if when applying drift to a dataset the difference in the predictions are affected more than a tolerance. For example, in the regression case, it looks (by default) the sum of the squared differences of the predictions in the non-drifted data and the drifted data. As in the previous test, we can also specify a function to specify how to calculate the difference between predictions. In that case, the inferface of the function must be `eval_fn(y_hat, y_hat_drifted)`, where `y_hat` will be the predictions of the non-drifted dataset and `y_hat_drifted` the preditions of the drifted dataset.\n",
    "\n",
    "As before, the applied drift is controlled by the `drift_type` and `drift_args` arguments. Let's apply shift drift on  `total_bill` column in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9745ce2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "c9745ce2",
    "outputId": "2212810a-f30d-4e54-c594-c386833555a7"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. Prediction loss drifted above tolerance = 5.000 (loss = 27136.125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m drift_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_bill\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m100.\u001b[39m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m DriftPredictionsResistanceTest(\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m pipeline_lr, \n\u001b[1;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m tips[cat_feats \u001b[38;5;241m+\u001b[39m num_feats], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/model_tests.py:555\u001b[0m, in \u001b[0;36mDriftPredictionsResistanceTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY, drifted_Y)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance:\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. Prediction loss drifted above tolerance = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m (loss = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)\n\u001b[1;32m    558\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. Prediction loss drifted above tolerance = 5.000 (loss = 27136.125)"
     ]
    }
   ],
   "source": [
    "from mercury.robust.model_tests import DriftPredictionsResistanceTest\n",
    "\n",
    "drift_args = {\n",
    "    'cols' : ['total_bill'], \n",
    "    'force' : 100.\n",
    "}\n",
    "test = DriftPredictionsResistanceTest(\n",
    "    model = pipeline_lr, \n",
    "    X = tips[cat_feats + num_feats], \n",
    "    drift_type = 'shift_drift', \n",
    "    drift_args = drift_args,\n",
    "    tolerance = 5\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54029b79",
   "metadata": {
    "id": "54029b79"
   },
   "source": [
    "Now to the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1773b54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "d1773b54",
    "outputId": "75bfc29f-784a-4aeb-fea1-97421ffd9cc1"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed. Prediction loss drifted above tolerance = 5.000 (loss = 8810.820)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m drift_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_bill\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m100.\u001b[39m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m test \u001b[38;5;241m=\u001b[39m DriftPredictionsResistanceTest(\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m pipeline_rf, \n\u001b[1;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m tips[cat_feats \u001b[38;5;241m+\u001b[39m num_feats], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/model_tests.py:555\u001b[0m, in \u001b[0;36mDriftPredictionsResistanceTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY, drifted_Y)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance:\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed. Prediction loss drifted above tolerance = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m (loss = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)\n\u001b[1;32m    558\u001b[0m     )\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed. Prediction loss drifted above tolerance = 5.000 (loss = 8810.820)"
     ]
    }
   ],
   "source": [
    "drift_args = {\n",
    "    'cols' : ['total_bill'], \n",
    "    'force' : 100.\n",
    "}\n",
    "test = DriftPredictionsResistanceTest(\n",
    "    model = pipeline_rf, \n",
    "    X = tips[cat_feats + num_feats], \n",
    "    drift_type = 'shift_drift', \n",
    "    drift_args = drift_args,\n",
    "    tolerance = 5\n",
    ")\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fcebd",
   "metadata": {
    "id": "572fcebd"
   },
   "source": [
    "We see that both models fail to pass the test in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b64b9f",
   "metadata": {
    "id": "a9b64b9f"
   },
   "source": [
    "<a id=\"sample_leaking\"></a>\n",
    "### Sample Leaking Test\n",
    "\n",
    "The `SampleLeakingTest` looks if our test set contains samples that are identical to samples that are in our train dataset. In some use cases is fine to have some identical samples in test and train dataset. However, in some cases those identical samples might appear because errors in our data pipelines. For those cases, it might be useful to use the `SampleLeakingTest` \n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d6796f9",
   "metadata": {
    "id": "5d6796f9"
   },
   "outputs": [],
   "source": [
    "path_dataset = \"./data/credit/\"\n",
    "uci_credit = pd.read_csv(path_dataset + \"UCI_Credit_card.csv\")\n",
    "uci_credit = uci_credit.drop('ID', axis=1)\n",
    "\n",
    "uci_credit[\"SEX\"] = uci_credit[\"SEX\"].astype(str)\n",
    "uci_credit[\"EDUCATION\"] = uci_credit[\"EDUCATION\"].astype(str)\n",
    "uci_credit[\"MARRIAGE\"] = uci_credit[\"MARRIAGE\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a7e050d",
   "metadata": {
    "id": "0a7e050d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(uci_credit, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293bb48c",
   "metadata": {
    "id": "293bb48c"
   },
   "source": [
    "We instantiate the `SampleLeakingTest` by passing the training and test datasets. Optionally, we can set the `threshold` parameter (by default is 0) to allow a determined number of repeated samples. We can also specify a list of columns that we want to ignore when checking if a sample is exactly the same using the parameter `ignore_feats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58f65717",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "58f65717",
    "outputId": "495b0328-f9b7-4ea9-9eb1-d3e7c234e06a"
   },
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Num of samples in test set that appear in train set is 11 (a proportion of 0.002 test samples )and the max allowed is 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmercury\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobust\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_tests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SampleLeakingTest\n\u001b[1;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m SampleLeakingTest(base_dataset\u001b[38;5;241m=\u001b[39mdf_train, test_dataset\u001b[38;5;241m=\u001b[39mdf_test)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:987\u001b[0m, in \u001b[0;36mSampleLeakingTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_duplicated_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_sample_leaking()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_high_number_of_duplicates():\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError(\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum of samples in test set that appear in train set is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_duplicated_test\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(a proportion of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_duplicated_test\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset), \u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test samples )\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the max allowed is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Num of samples in test set that appear in train set is 11 (a proportion of 0.002 test samples )and the max allowed is 0"
     ]
    }
   ],
   "source": [
    "from mercury.robust.data_tests import SampleLeakingTest\n",
    "test = SampleLeakingTest(base_dataset=df_train, test_dataset=df_test)\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f757ffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f757ffa",
    "outputId": "67993c3b-739d-453b-92e0-38ef4b119a39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_duplicated': 11, 'percentage_duplicated': 0.0018333333333333333}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76199df0",
   "metadata": {
    "id": "76199df0"
   },
   "source": [
    "As we have some samples in the test set that also appear in the train set, the test fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai3WxQQSmLWl",
   "metadata": {
    "id": "ai3WxQQSmLWl"
   },
   "source": [
    "\n",
    "\n",
    "## References\n",
    "<a id=\"[1]\">[1]</a> \n",
    "Efficient Intent Detection with Dual Sentence Encoders. https://arxiv.org/abs/2003.04807.\n",
    "Iigo Casanueva and Tadas Temcinas and Daniela Gerz and Matthew Henderson and Ivan Vulic.\n",
    "Data available at https://github.com/PolyAI-LDN/task-specific-datasets\n",
    "\n",
    "<a id=\"[2]\">[2]</a>\n",
    "Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IK2iRJ4-A-PG",
   "metadata": {
    "id": "IK2iRJ4-A-PG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
