
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../data_tests/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.45">
    
    
      
        <title>model tests - mercury-robust</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-tests" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="mercury-robust" class="md-header__button md-logo" aria-label="mercury-robust" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5zM6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            mercury-robust
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              model tests
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/BBVA/mercury-robust/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    mercury-robust
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="mercury-robust" class="md-nav__button md-logo" aria-label="mercury-robust" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5zM6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5"/></svg>

    </a>
    mercury-robust
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/BBVA/mercury-robust/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    mercury-robust
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Api
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Api
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../basetests/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base tests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_tests/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data tests
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    model tests
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    model tests
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mercury.robust.model_tests" class="md-nav__link">
    <span class="md-ellipsis">
      model_tests
    </span>
  </a>
  
    <nav class="md-nav" aria-label="model_tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest" class="md-nav__link">
    <span class="md-ellipsis">
      ClassificationInvarianceTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ClassificationInvarianceTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest.get_examples_failed" class="md-nav__link">
    <span class="md-ellipsis">
      get_examples_failed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftMetricResistanceTest" class="md-nav__link">
    <span class="md-ellipsis">
      DriftMetricResistanceTest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftPredictionsResistanceTest" class="md-nav__link">
    <span class="md-ellipsis">
      DriftPredictionsResistanceTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DriftPredictionsResistanceTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftPredictionsResistanceTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.FeatureCheckerTest" class="md-nav__link">
    <span class="md-ellipsis">
      FeatureCheckerTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeatureCheckerTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.FeatureCheckerTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelReproducibilityTest" class="md-nav__link">
    <span class="md-ellipsis">
      ModelReproducibilityTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ModelReproducibilityTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelReproducibilityTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelSimplicityChecker" class="md-nav__link">
    <span class="md-ellipsis">
      ModelSimplicityChecker
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.TreeCoverageTest" class="md-nav__link">
    <span class="md-ellipsis">
      TreeCoverageTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TreeCoverageTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.TreeCoverageTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mercury.robust.model_tests" class="md-nav__link">
    <span class="md-ellipsis">
      model_tests
    </span>
  </a>
  
    <nav class="md-nav" aria-label="model_tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest" class="md-nav__link">
    <span class="md-ellipsis">
      ClassificationInvarianceTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ClassificationInvarianceTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest.get_examples_failed" class="md-nav__link">
    <span class="md-ellipsis">
      get_examples_failed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ClassificationInvarianceTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftMetricResistanceTest" class="md-nav__link">
    <span class="md-ellipsis">
      DriftMetricResistanceTest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftPredictionsResistanceTest" class="md-nav__link">
    <span class="md-ellipsis">
      DriftPredictionsResistanceTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DriftPredictionsResistanceTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.DriftPredictionsResistanceTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.FeatureCheckerTest" class="md-nav__link">
    <span class="md-ellipsis">
      FeatureCheckerTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeatureCheckerTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.FeatureCheckerTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelReproducibilityTest" class="md-nav__link">
    <span class="md-ellipsis">
      ModelReproducibilityTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ModelReproducibilityTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelReproducibilityTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.ModelSimplicityChecker" class="md-nav__link">
    <span class="md-ellipsis">
      ModelSimplicityChecker
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.TreeCoverageTest" class="md-nav__link">
    <span class="md-ellipsis">
      TreeCoverageTest
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TreeCoverageTest">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mercury.robust.model_tests.TreeCoverageTest.run" class="md-nav__link">
    <span class="md-ellipsis">
      run
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="model-tests">Model Tests</h1>


<div class="doc doc-object doc-module">



<h2 id="mercury.robust.model_tests" class="doc doc-heading">
            <code>mercury.robust.model_tests</code>


</h2>

    <div class="doc doc-contents first">








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.ClassificationInvarianceTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">ClassificationInvarianceTest</span><span class="p">(</span><span class="n">original_samples</span><span class="p">,</span> <span class="n">perturbed_samples</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predict_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">check_total_errors_rate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code></p>


        <p>The idea of the <code>ClassificationInvarianceTest</code> is to check that if we apply a label-preserving perturbation the prediction of the
model shouldn't change.</p>
<p>This class helps to check this by checking the number of samples where the conditional of preserving the label doesn't hold and raising
an error if the percentage of samples where the label is not preserved is higher than a specified threshold. We must pass to the test
the original samples and the already generated perturbed samples.</p>
<p>When calling run(), a exception <code>FailedTestError</code> is raised if the test fails. Additionally, the next attributes are filled:</p>
<div class="codehilite"><pre><span></span><code><span class="k">-</span> preds_original_samples: stores the predictions for the original samples
<span class="k">-</span> preds_perturbed_samples: stores the predictions for perturbed samples
<span class="k">-</span> pred_is_different: stores for each sample a boolean array indicating if the predictions for the perturbed samples are different
    to the original sample
<span class="k">-</span> num_failed_per_sample: stores for each sample the number of perturbations where the prediction is different to the original sample
<span class="k">-</span> num_perturbed_per_sample: stores for each samples the number of perturbations
<span class="k">-</span> samples_with_errors: boolean array containing which samples contain errors
<span class="k">-</span> rate_samples_with_errors: the percentage of samples that contains at least one perturbed sample that the model predicted
    a different label.
<span class="k">-</span> total_rate_errors: the total percentage of perturbed samples that the model predicted a different label
</code></pre></div>


<details class="this-test-is-based-on-the-paper" open>
  <summary>This test is based on the paper</summary>
  <p><a href="https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf">'Beyond Accuracy: Behavioral Testing of NLP Models with CheckList'</a></p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>original_samples</code>
            </td>
            <td>
                  <code>Union(List[str], np.array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List or array containing the original samples</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>perturbed_samples</code>
            </td>
            <td>
                  <code>Union(List[List[str]], np.array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List or array containing the perturbed samples. Each element
of the list or each row of the array contains one or several perturbed samples corresponding to the sample in the
same position/index in <code>original_samples</code></p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>BaseEstimator</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model being evaluated. The model must be already trained. It is assumed to have a sklearn-like compliant
predict() method that works on the <code>original_samples</code> and <code>perturbed_samples</code> and returns a vector with the
the predictions. Alternatively, you can pass a <code>predict_fn</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>predict_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function that given the samples returns the predicted labels. Only used if <code>model</code> argument is
None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>if the percentage of samples with errors is higher than this threshold, then a <code>FailedTestError</code>
will be raised. Default value is 0.05</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>check_total_errors_rate</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>this indicates what to consider as percentage of errors. If True, then each perturbed
sample counts to calculate the rate. If False, then the rate is calculated with the number of samples independently
of how many perturbations each sample has. Default value is True</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">original_samples</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sample1&quot;</span><span class="p">,</span> <span class="s2">&quot;sample2&quot;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">perturbed_samples</span> <span class="o">=</span> <span class="p">[</span>
<span class="o">...</span>    <span class="s2">&quot;perturbed_sample_1 for sample1&quot;</span><span class="p">,</span> <span class="s2">&quot;perturbed_sample_2 for sample1&quot;</span><span class="p">,</span>
<span class="o">...</span>    <span class="s2">&quot;perturbed_sample_1 for sample2&quot;</span><span class="p">,</span> <span class="s2">&quot;perturbed_sample2 for sample2&quot;</span>
<span class="o">...</span> <span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">ClassificationInvarianceTest</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">original_samples</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">perturbed_samples</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">predict_fn</span><span class="o">=</span><span class="n">my_model</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">check_total_errors_rate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Invariance Test&quot;</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">original_samples</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">],</span>
    <span class="n">perturbed_samples</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">],</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;BaseEstimator&quot;</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">predict_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">check_total_errors_rate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">original_samples</span> <span class="o">=</span> <span class="n">original_samples</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">perturbed_samples</span> <span class="o">=</span> <span class="n">perturbed_samples</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predict_fn</span> <span class="o">=</span> <span class="n">predict_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">check_total_errors_rate</span> <span class="o">=</span> <span class="n">check_total_errors_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_samples</span><span class="p">)</span>

    <span class="c1"># Attributes for results</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds_original_samples</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds_perturbed_samples</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pred_is_different</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_failed_per_sample</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_perturbed_per_sample</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">samples_with_errors</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rate_samples_with_errors</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_rate_errors</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.ClassificationInvarianceTest.get_examples_failed" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_examples_failed</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_perturbed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Returns examples of samples that failed.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_samples</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>number of samples to recover.</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_perturbed</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>for each sample, how many failed perturbations to recover.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_examples_failed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_perturbed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns examples of samples that failed.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_samples (int): number of samples to recover.</span>
<span class="sd">        n_perturbed (int): for each sample, how many failed perturbations to recover.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">selected_failed_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_random_failed_samples</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="c1"># Get perturbations that failed for each selected sample</span>
    <span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx_selected</span> <span class="ow">in</span> <span class="n">selected_failed_samples</span><span class="p">:</span>
        <span class="n">selected_perturbed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_random_failed_perturbations</span><span class="p">(</span><span class="n">idx_selected</span><span class="p">,</span> <span class="n">n_perturbed</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx_perturbed</span> <span class="ow">in</span> <span class="n">selected_perturbed</span><span class="p">:</span>
            <span class="n">sample_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_samples</span><span class="p">[</span><span class="n">idx_selected</span><span class="p">]</span>
            <span class="n">sample_perturbed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbed_samples</span><span class="p">[</span><span class="n">idx_selected</span><span class="p">][</span><span class="n">idx_perturbed</span><span class="p">]</span>
            <span class="n">pred_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds_original_samples</span><span class="p">[</span><span class="n">idx_selected</span><span class="p">]</span>
            <span class="n">pred_perturbed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preds_perturbed_samples</span><span class="p">[</span><span class="n">idx_selected</span><span class="p">][</span><span class="n">idx_perturbed</span><span class="p">]</span>
            <span class="n">examples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sample_original</span><span class="p">,</span> <span class="n">sample_perturbed</span><span class="p">,</span> <span class="n">pred_original</span><span class="p">,</span> <span class="n">pred_perturbed</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;original&quot;</span><span class="p">,</span> <span class="s2">&quot;perturbed&quot;</span><span class="p">,</span> <span class="s2">&quot;pred_original&quot;</span><span class="p">,</span> <span class="s2">&quot;pred_perturbed&quot;</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.ClassificationInvarianceTest.run" class="doc doc-heading">
            <code class=" language-python"><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>run the test</p>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;run the test&quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_check_args</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">preds_original_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_predictions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_samples</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_changes_in_perturbed_samples_predictions</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_errors_rate</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fail_test_if_high_error</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.DriftMetricResistanceTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">DriftMetricResistanceTest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">drift_type</span><span class="p">,</span> <span class="n">drift_args</span><span class="p">,</span> <span class="n">names_categorical</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataset_schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mercury.robust.model_tests.DriftPredictionsResistanceTest" href="#mercury.robust.model_tests.DriftPredictionsResistanceTest">DriftPredictionsResistanceTest</a></code>, <code><span title="mercury.robust.basetests.TaskInferrer">TaskInferrer</span></code></p>


        <p>This test checks the robustness of a trained model to drift in the X dataset. It uses the model to predict the Y_no_drifted
from the given X. Then, it applies some drift to the data in X by using a <code>BatchDriftGenerator</code> object and calculates
Y_drifted. Then calculates a metric using Y_true with Y_no_drifted on the one hand and using Y_true with Y_drifted on the other
hand. If the difference between these two metrics diverge more than some given tolerance value, the test fails.
This test does only one verification. If we need doing more than one drift check, just apply multiple tests with
appropriate names to simplify following up the results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>Any</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model being evaluated. The model must be already trained and will not be trained again by this test. It is
    assumed to have a sklearn-like compliant predict() method that works on the dataset and returns a vector that is accepted by
the evaluation function.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A pandas dataset that can be used by the model's predict() method and whose predicted values will be used as
    the ground truth drift measurement.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>Y</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pandas.DataFrame">DataFrame</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>array with the ground truth values. It will be used to calculate the metric for the
    non-drifted dataset and for the drifted dataset</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drift_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the method of a BatchDriftGenerator specifying the type of drift to be applied. E.g., "shift_drift",
"scale_drift", ... You can check the class BatchDriftGenerator in _drift_simulation to see all available types</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drift_args</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary with the argument expected by the drift method. E.g., {cols: ['a', 'b'], iqr: [1.12, 1.18]} for
"scale_drift".</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>names_categorical</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optional list with the names of the categorical variables. If this is used, the
    internal <code>BatchDriftGenerator</code> will use a <code>DataSchema</code> object to fully define the variables in X as either categorical
(if in the list) or continuous (otherwise). This allows automatically selecting the columns without using the <code>cols</code> argument
in <code>drift_args</code>. If this parameter is not given, the <code>DataSchema</code> is not initially defined and either you select the columns
manually by declaring a <code>cols</code> argument in <code>drift_args</code> or the <code>BatchDriftGenerator</code> will create a <code>DataSchema</code> that
automatically infers the column types.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataset_schema</code>
            </td>
            <td>
                  <code><span title="mercury.dataschema.DataSchema">DataSchema</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alternatively, you can provide a pre built schema for an even higher level of control. If
    you use this argument, <code>names_categorical</code> is not used. The schema fully defines binary, categorical, discrete or continuous.
If you still define the <code>cols</code> argument in <code>drift_args</code>, that selection will prevail over whatever is in <code>dataset_schema</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>: the evaluation function to use to calculate the metric. If passed, the interface of the function must
    be <code>eval_fn(y_true, y_hat)</code>. If not used, the mean absolute error will be used for regression and the accuracy for
classification.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A real value to be compared with the difference of the computed metric with the non-drifted dataset and with the
drifted dataset.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>task</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>'classification' or 'regression'. If not given, the test will try to infer it from <code>Y</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">testing_dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">drift_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cols&#39;</span><span class="p">:</span> <span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="s1">&#39;percentile&#39;</span><span class="p">,</span> <span class="s1">&#39;method_params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;percentile&#39;</span><span class="p">:</span> <span class="mi">95</span><span class="p">}}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">DriftMetricResistanceTest</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">testing_dataset</span><span class="p">[</span><span class="n">features</span><span class="p">],</span>
<span class="o">...</span>    <span class="n">Y</span> <span class="o">=</span> <span class="n">testing_dataset</span><span class="p">[</span><span class="n">target</span><span class="p">],</span>
<span class="o">...</span>    <span class="n">drift_type</span> <span class="o">=</span> <span class="s1">&#39;outliers_drift&#39;</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">drift_args</span> <span class="o">=</span> <span class="n">drift_args</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>  <span class="c1"># The test will fail if the difference in the metric is more than 0.05</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
    <span class="n">drift_type</span><span class="p">,</span>
    <span class="n">drift_args</span><span class="p">,</span>
    <span class="n">names_categorical</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dataset_schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="nb">eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">drift_type</span><span class="p">,</span> <span class="n">drift_args</span><span class="p">,</span> <span class="n">names_categorical</span><span class="p">,</span> <span class="n">dataset_schema</span><span class="p">,</span> <span class="nb">eval</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Y_true</span> <span class="o">=</span> <span class="n">Y</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric_no_drifted</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric_drifted</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric_diff</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.DriftPredictionsResistanceTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">DriftPredictionsResistanceTest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">drift_type</span><span class="p">,</span> <span class="n">drift_args</span><span class="p">,</span> <span class="n">names_categorical</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataset_schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code></p>


        <p>This test checks the robustness of a trained model to drift in the X dataset. It uses the model to predict the Y from the given X and
uses that <code>Y</code> as a ground truth. Then, it applies some drift to the data in X by using a <code>BatchDriftGenerator</code> object and does a new
prediction <code>drifted_Y</code> using the drifted dataset. If both the <code>Y</code> and <code>drifted_Y</code> diverge by more that some given tolerance value,
the test fails. This test does only one verification. If we need doing more than one drift check, just apply multiple tests with
appropriate names to simplify following up the results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>Any</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model being evaluated. The model must be already trained and will not be trained again by this test. It is assumed
    to have a sklearn-like compliant predict() method that works on the dataset and returns a vector that is accepted by the
evaluation function.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A pandas dataset that can be used by the model's predict() method and whose predicted values will be used as the
    ground truth drift measurement.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drift_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the method of a BatchDriftGenerator specifying the type of drift to be applied. E.g., "shift_drift",
"scale_drift", ... You can check the class BatchDriftGenerator in _drift_simulation to see all available types</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drift_args</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary with the argument expected by the drift method. E.g., {cols: ['a', 'b'], iqr: [1.12, 1.18]} for
"scale_drift".</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>names_categorical</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optional list with the names of the categorical variables. If this is used, the
    internal <code>BatchDriftGenerator</code> will use a <code>DataSchema</code> object to fully define the variables in X as either categorical (if
in the list) or continuous (otherwise). This allows automatically selecting the columns without using the <code>cols</code> argument
in <code>drift_args</code>. If this parameter is not given, the <code>DataSchema</code> is not initially defined and either you select the columns
manually by declaring a <code>cols</code> argument in <code>drift_args</code> or the <code>BatchDriftGenerator</code> will create a <code>DataSchema</code> that
automatically infers the column types.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataset_schema</code>
            </td>
            <td>
                  <code><span title="mercury.dataschema.DataSchema">DataSchema</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Alternatively, you can provide a pre built schema for an even higher level of control. If
    you use this argument, <code>names_categorical</code> is not used. The schema fully defines binary, categorical, discrete or continuous.
If you still define the <code>cols</code> argument in <code>drift_args</code>, that selection will prevail over whatever is in <code>dataset_schema</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given, an evaluation function that defines how "different" the predictions are. The function must
    accept two vectors returned by model.predict() and return some positive value that indicates the difference in the predictions
and is compared with <code>tolerance</code>. If not given, then a sum of squared differences will be used unless the <code>model.predict()</code>
method generates the hard labels for a multi-class classification problem. In this last case, the <code>eval</code> function will be a
function to compute the number of different predictions.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A real value to be compared with the result of the evaluation function. Note that the purpose of the test is to
    check if the model is robust to the introduced drift. Therefore, the test will fail when the result (named as <code>loss</code>) is
higher than the tolerance, meaning the model predictions considerably change with the introduced drift. When the test fails,
you can see the value returned by the <code>eval</code> function in the RuntimeError message displayed as <code>loss</code>.</p>
              </div>
            </td>
            <td>
                  <code>0.001</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">mercury.robust.model_tests</span> <span class="kn">import</span> <span class="n">DriftPredictionsResistanceTest</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">DriftPredictionsResistanceTest</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">trained_model</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">drift_type</span> <span class="o">=</span> <span class="s2">&quot;shift_drift&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">drift_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cols&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">],</span> <span class="s1">&#39;force&#39;</span><span class="p">:</span> <span class="mf">100.</span><span class="p">},</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">tolerance</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">drift_type</span><span class="p">,</span>
    <span class="n">drift_args</span><span class="p">,</span>
    <span class="n">names_categorical</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dataset_schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="nb">eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dataset_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">BatchDriftGenerator</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">dataset_schema</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">names_categorical</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">BatchDriftGenerator</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">DataSchema</span><span class="p">()</span><span class="o">.</span><span class="n">generate_manual</span><span class="p">(</span>
                <span class="n">dataframe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                <span class="n">categ_columns</span><span class="o">=</span><span class="n">names_categorical</span><span class="p">,</span>
                <span class="n">discrete_columns</span><span class="o">=</span><span class="p">[],</span>
                <span class="n">binary_columns</span><span class="o">=</span><span class="p">[],</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">BatchDriftGenerator</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">,</span> <span class="n">drift_type</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fun</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;drift_type = </span><span class="si">%s</span><span class="s2"> must be a method of BatchDriftGenerator.&quot;</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">drift_args</span> <span class="o">=</span> <span class="n">drift_args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span> <span class="o">=</span> <span class="nb">eval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.DriftPredictionsResistanceTest.run" class="doc doc-heading">
            <code class=" language-python"><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Runs the test.</p>
<p>Raises <code>FailedTestError</code> with a descriptive message if any of the attempts fail.</p>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the test.</span>

<span class="sd">    Raises `FailedTestError` with a descriptive message if any of the attempts fail.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">drifted_Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_drifted_Y</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">eval_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_default_eval_fn</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">eval_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="n">drifted_Y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="n">drifted_Y</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
            <span class="s2">&quot;Test failed. Prediction loss drifted above tolerance = </span><span class="si">%.3f</span><span class="s2"> (loss = </span><span class="si">%.3f</span><span class="s2">)&quot;</span>
            <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.FeatureCheckerTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">FeatureCheckerTest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_fn_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">importance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">num_tries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">remove_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code></p>


        <p>This model robustness test checks if training the models using less columns in the dataframe can achieve identical results.
To do so, it uses the variable importance taken from the model itself or estimated using a mercury.explainability explainer
(ShuffleImportanceExplainer). It does a small number of attempts at removing unimportant variables and "fails if it succeeds",
since success implies that a smaller, therefore more efficient, dataset should be used instead. The purpose of this test is
not to find that optimal dataset. That can be achieved by removing the columns identified as unimportant and iterating.</p>
<p><strong>NOTE</strong>: This class will retrain (fit) the model several times resulting in the model being altered as a side effect. Make
copies of your model before using this tool. This tool is intended as a diagnostic tool.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[Estimator, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model being evaluated. The model is assumed to comply to a minimalistic sklearn-like interface. More precisely:
1. It must have a fit() method that works on the dataset and the dataset with some columns removed. It is important that each
time the method fit() is called the model is trained from scratch (ie does not perform incremental training).
2. It must have a predict() method that works on the dataset and returns a vector that is accepted by the evaluation function.
3. If the argument <code>importance</code> is used, it must have an attribute with that name containing a list of (value, column_name)
tuples which is consistent with many sklearn models.
Alternatively, you can provide a function that creates a model or pipeline. This is useful in models or pipelines where
removing columns from a dataframe raises an error because it expects the removed column. In this case, the interface of
the function is model_fn(dataframe, model_args), where dataframe is the input pandas dataframe with the features already
removed and model_fn_args is a dictionary with optional parameters that can be passed to the function. Importantly,
this function just needs to create the model (unfitted) instance, but not to perform the training</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_fn_args</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>if you are using a function in <code>model</code> parameter, you can use this argument to provide arguments to that function.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The pandas dataset used for training the model, possibly with some columns removed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the target variable predicted by the model which must be one columns in the train dataset.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>test</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given, a separate dataset with identical column structure used for the evaluation parts. Otherwise, the train dataset
will be used instead.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>importance</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given, the name of a property in the model is updated by a fit() call. It must contain the importance of the
columns as a list of (value, column_name) tuples. Otherwise, the importance of the variables will be estimated using a
mercury.explainer ShuffleImportanceExplainer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given, an evaluation function that defines what "identical" results are. The function must accept two vectors returned
by model.predict() and return some positive value that is smaller than <code>tolerance</code> if "identical". Otherwise a sum of squared
differences will be used instead.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A real value to be compared with the result of the evaluation function. Note that the purpose of the test is finding
unimportant variables. Therefore, the test will fail when the result (named as <code>loss</code>) is smaller than the tolerance, meaning
the model could work "identically" well with less variables. When the test fails, you can see the value returned by the <code>eval</code>
function in the RuntimeError message displayed as <code>loss</code>.</p>
              </div>
            </td>
            <td>
                  <code>0.001</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_tries</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The total number of column removal tries the test should do before passing. This value times <code>remove_num</code> must be
smaller than the number of columns (Y excluded).</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>remove_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of columns removed at each try.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">mercury.robust.model_tests</span> <span class="kn">import</span> <span class="n">FeatureCheckerTest</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">FeatureCheckerTest</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">train</span><span class="o">=</span><span class="n">df_train</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">target</span><span class="o">=</span><span class="s2">&quot;label_col&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">test</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">num_tries</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">remove_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">tolerance</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_test</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Estimator&quot;</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">test</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_fn_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">importance</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="nb">eval</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">num_tries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">remove_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model_fn_args</span> <span class="o">=</span> <span class="n">model_fn_args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">test</span> <span class="k">if</span> <span class="n">test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">importance</span> <span class="o">=</span> <span class="n">importance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval</span> <span class="o">=</span> <span class="nb">eval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">remove_num</span> <span class="o">=</span> <span class="n">remove_num</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_tries</span> <span class="o">=</span> <span class="n">num_tries</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.FeatureCheckerTest.run" class="doc doc-heading">
            <code class=" language-python"><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Runs the test.</p>
<p>Raises <code>FailedTestError</code> with a descriptive message if any of the attempts fail.</p>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the test.</span>

<span class="sd">    Raises `FailedTestError` with a descriptive message if any of the attempts fail.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_num</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_tries</span>

    <span class="n">X_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
    <span class="n">Y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

    <span class="c1"># Fit model with all the features</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fit_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

    <span class="n">X_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">remove</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_least_important</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span> <span class="o">!=</span> <span class="n">N</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Wrong arguments. Not enough columns for remove_num*num_tries.&quot;</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_tries</span><span class="p">):</span>
        <span class="n">exclude</span> <span class="o">=</span> <span class="n">remove</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">remove_num</span><span class="p">]</span>
        <span class="n">remove</span> <span class="o">=</span> <span class="n">remove</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">remove_num</span><span class="p">:]</span>

        <span class="n">exclude</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>

        <span class="n">x_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">]</span>

        <span class="n">X_alt_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">x_cols</span><span class="p">]</span>

        <span class="c1"># Fit model with the removed features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_model</span><span class="p">(</span><span class="n">X_alt_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

        <span class="n">X_alt_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">x_cols</span><span class="p">]</span>
        <span class="n">Y_alt_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_alt_test</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">Y_hat</span> <span class="o">-</span> <span class="n">Y_alt_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y_alt_hat</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">exclude</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
                <span class="s2">&quot;Test failed. A model fitted removing columns [</span><span class="si">%s</span><span class="s2">] is identical within tolerance </span><span class="si">%.3f</span><span class="s2"> (loss = </span><span class="si">%.3f</span><span class="s2">)&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">exclude</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.ModelReproducibilityTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">ModelReproducibilityTest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">train_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold_eval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">predict_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predict_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold_yhat</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">yhat_allowed_diff</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">test_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code></p>


        <p>This test checks if the training of a model is reproducible. It does so by training the model two times
and checking whether they give the same evaluation metric and predictions. If the difference in
the evaluation metric is higher than <code>threshold_eval</code> parameter then the test fails. Similarly, if
the percentage of different predictions is higher than <code>threshold_yhat</code> then the test fails.
You can check only one of the checks (the evaluation metric and predictions) or only one of them.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>(BaseEstimator, <span title="tf.keras.Model">Model</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Unfitted model that we are checking reproducibility</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_dataset</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The pandas dataset used for training the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the target variable predicted by the model which must be one column in
the train dataset.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function called to train the model. The interface of the function is
train_fn(model, X, y, train_params) and returns the fitted model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_params</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Params to use for training. It is passed as a parameter to the <code>train_fn</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function called to evaluate the model. The interface of the function is
eval_fn(model, X, y, eval_params) and returns a float. If None, then the check of looking if
training two times produces the same evaluation metric won't be performed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_params</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Params to use for evaluation. It is passed as a parameter to the <code>eval_fn</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold_eval</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>difference that we are able to tolerate in the evaluation function in order
to pass the test. If the difference of the evaluation metric when training the model two times
is higher than the threshold, then the test fails. Default value is 0</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>predict_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function called to get the predictions of a dataset once the model is trained.
The interface of the function is predict_fn(model, X, predict_params) and returns the predictions.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>predict_params</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Params to use for prediction. It is passed as a parameter to the <code>predict_fn</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold_yhat</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>predict_fn</code> is given, this is the percentage of different predictions that we are
can tolerate without making the test fail. A prediction from the model trained two times is considered
different according to the parameter <code>yhat_allowed_diff</code>. Default value for <code>threshold_yhat</code> is 0,
meaning that with just one prediction different the test will fail.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>yhat_allowed_diff</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>difference that we can tolerate in order to consider that a sample has the
same prediction from two models. If a prediction of the model trained two times differ by more than
<code>yhat_allowed_diff</code> then that prediction is considered to be different. Default value is 0.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>test_dataset</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If given, a separate dataset with identical column structure used for the
evaluation parts.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Define necessary functions for model training, evaluation, and getting predictions</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">return</span> <span class="n">model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">pred_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1">#Create and run test</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">mercury.robust.model_tests</span> <span class="kn">import</span> <span class="n">ModelReproducibilityTest</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">ModelReproducibilityTest</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;label_col&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">train_fn</span> <span class="o">=</span> <span class="n">train_model_fn</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">eval_fn</span> <span class="o">=</span> <span class="n">eval_model_fn</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">threshold_eval</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">predict_fn</span> <span class="o">=</span> <span class="n">get_predictions_fn</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">epsilon_yhat</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">df_test</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;BaseEstimator&quot;</span><span class="p">,</span> <span class="s2">&quot;tf.keras.Model&quot;</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="s2">&quot;pd.DataFrame&quot;</span><span class="p">,</span>  <span class="c1"># noqa: F821,</span>
    <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">train_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">train_params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">eval_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">eval_params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">threshold_eval</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">predict_params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold_yhat</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">yhat_allowed_diff</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="s2">&quot;pd.DataFrame&quot;</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_fn</span> <span class="o">=</span> <span class="n">train_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_params</span> <span class="o">=</span> <span class="n">train_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span> <span class="o">=</span> <span class="n">eval_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_params</span> <span class="o">=</span> <span class="n">eval_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_eval</span> <span class="o">=</span> <span class="n">threshold_eval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predict_fn</span> <span class="o">=</span> <span class="n">predict_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predict_params</span> <span class="o">=</span> <span class="n">predict_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_yhat</span> <span class="o">=</span> <span class="n">threshold_yhat</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">yhat_allowed_diff</span> <span class="o">=</span> <span class="n">yhat_allowed_diff</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.ModelReproducibilityTest.run" class="doc doc-heading">
            <code class=" language-python"><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Runs the test.</p>
<p>Raises FailedTestError if training is not reproducible</p>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the test.</span>

<span class="sd">    Raises FailedTestError if training is not reproducible</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">X_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

    <span class="c1"># Clone the model</span>
    <span class="n">model_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clone_unfitted_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clone_unfitted_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># Train the models</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must provide a valid train_fn to train the model&quot;</span><span class="p">)</span>
    <span class="n">model_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_fn</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_params</span><span class="p">)</span>
    <span class="n">model_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_fn</span><span class="p">(</span><span class="n">model_2</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_params</span><span class="p">)</span>

    <span class="c1"># Check that at least one of eval_fn or predict_fn are specified</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one of eval_fn or predict_fn must be specified&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Check evaluation on train</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_diff_in_eval</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">model_2</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Eval metric different in train dataset when training two times (</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_2</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The max difference allowed is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_eval</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The model is not reproducible.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Check evaluation on test</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_diff_in_eval</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">model_2</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Eval metric different in test dataset when training two times (</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_2</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The max difference allowed is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_eval</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The model is not reproducible.&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Check evaluation on train</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_diff_in_predictions</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">model_2</span><span class="p">,</span> <span class="n">X_train</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Percentage of different predictions in training set is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">diff</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> when training two times and the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;maximum allowed is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_yhat</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The model is not reproducible.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Check evaluation on test</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_diff_in_predictions</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">model_2</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Percentage of different predictions in test set is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">diff</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> when training two times and the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;maximum allowed is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_yhat</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;The model is not reproducible.&quot;</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.ModelSimplicityChecker" class="doc doc-heading">
              <code class=" language-python"><span class="n">ModelSimplicityChecker</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">baseline_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_feats</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predict_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">encode_cat_feats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_num_feats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_predictions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">schema_custom_feature_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataset_schema</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code>, <code><span title="mercury.robust.basetests.TaskInferrer">TaskInferrer</span></code></p>


        <p>This test looks if a trained model has a simple baseline which trained in the same dataset
gives better or similar performance on a test dataset. If not specified, the baseline is considered
a LogisticRegression model for classification tasks and LinearRegression model for regression tasks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[BaseEstimator, <span title="tf.keras.Model">Model</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>the trained model which we will compare against
a baseline model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>X_train</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pandas.DataFrame">DataFrame</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>features of train dataset used to train the <code>model</code>.
This same dataset will be used to train the baseline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y_train</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pandas.DataFrame">DataFrame</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>targets of train dataset used to train the <code>model</code>.
This same dataset will be used to train the baseline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>X_test</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pandas.DataFrame">DataFrame</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>features of test dataset which will be used to evaluate
the <code>model</code> and the baseline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y_test</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pandas.DataFrame">DataFrame</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>targets of test dataset which will be used to evaluate
the <code>model</code> and the baseline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ignore_feats</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Features which won't be used in the <code>baseline_model</code>. Only use when <code>X_train</code> and <code>X_test</code>
are pandas dataframes.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>baseline_model</code>
            </td>
            <td>
                  <code>BaseEstimator</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional model that will be used as a baseline. It doesn't have to be
an sklearn model, however, it needs to implement the <code>fit()</code> and <code>predict()</code> methods. If not specified,
a LogisticRegression is used in case of classification and LinearRegression in case of regression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>task</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Task of the dataset. It must be either 'classification' or 'regression'. If None provided
  then it will be auto inferred from the <code>target</code> column.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span>[[<span title="numpy.ndarray">ndarray</span>], <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function which returns a metric to compare the performance of
the <code>model</code> against the baseline. The interface of the function is eval_fn(y_true, y_pred). Note that in
this test is assumed that the higher the metric the better the model, therefore if you use a metric which
lower means better then the <code>eval_fn</code> should return the negative of the metric. If not specified, the
accuracy score will be used in case of classification and R2 in case of regression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>predict_fn</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span>[[BaseEstimator], <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Custom predict function to obtain predictions from <code>model</code>.
The interface of the function is predict_fn(model, X_test). Note that by default this is None, and in that case,
the test will try to obtain the predictions using the <code>predict()</code> method of the <code>model</code>. That works in many cases
where you are using scikit-learn models and the predict function returns what the <code>eval_fn</code> is expecting.
However, in some case you might need to define a custom <code>predict_fn</code>. For example, when using a tf.keras
model and the accuracy_score as eval_fn, the <code>predict()</code> method from tf.keras model returns the
probabilities and the accuracy_score expects the classes, therefore you can use the <code>predict_fn</code> to obtain
the classes. Another alternative is to pass the already computed predictions using the <code>test_predictions</code>
parameter.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>test_predictions</code>
            </td>
            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>array of predictions of the test set obtained by the <code>model</code>. If given, the
test will use them instead of computing them using the <code>predict()</code> method of the <code>model</code> or the <code>predict_fn</code>
This might be useful in cases where you are creating multiple tests and you want to avoid to compute
the predictions each time.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The threshold to use when comparing the <code>model</code> and the baseline. It is used to establish
the limit to consider that the baseline performs similar or better than the <code>model</code>. Concretely, if the
baseline model performs worse than the <code>model</code> with a difference equal or higher than this threshold
then the test passes. Otherwise, if the baseline model performs better or performs worse but with a
difference lower than this threshold, then the test fails.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>encode_cat_feats</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool to indicate whether to encode categorical features as
one-hot-encoding. Note that if you specify it as False and your dataset has string column then the test will
raise an exception since the default baseline models won't be able to deal with string columns. Default
value is True</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>scale_num_feats</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool to indicate whether to scale the numeric features. If True, a StandardScaler
is used. Default value is True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>schema_custom_feature_map</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="mercury.dataschema.feature.FeatType">FeatType</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Internally, this test generates a DataSchema object. In case you find it makes
                       wrong feature type assignations to your features you can pass here a dictionary which
                       specify the feature type of the columns you want to fix. (See DataSchema. <code>force_types</code>
                       parameter for more info on this).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataset_schema</code>
            </td>
            <td>
                  <code><span title="mercury.dataschema.DataSchema">DataSchema</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Pre built schema. This argument is complementary to <code>schema_custom_feature_map</code>. In case you want to
            manually build your own DataSchema object, you can pass it here and the test will internally use it
            instead of the default, automatically built. If you provide this parameter, <code>schema_custom_feature_map</code>
            will not be used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">mercury.robust.model_tests</span> <span class="kn">import</span> <span class="n">ModelSimplicityChecker</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">ModelSimplicityChecker</span><span class="p">(</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="n">eval_fn</span> <span class="o">=</span> <span class="n">roc_auc_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;BaseEstimator&quot;</span><span class="p">,</span> <span class="s2">&quot;tf.keras.Model&quot;</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">X_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">y_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.Series&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">X_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">y_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pandas.Series&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">baseline_model</span><span class="p">:</span> <span class="s2">&quot;BaseEstimator&quot;</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">ignore_feats</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">eval_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s2">&quot;BaseEstimator&quot;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">encode_cat_feats</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">scale_num_feats</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">test_predictions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">schema_custom_feature_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">FeatType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dataset_schema</span><span class="p">:</span> <span class="n">DataSchema</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ignore_feats</span> <span class="o">=</span> <span class="n">ignore_feats</span> <span class="k">if</span> <span class="n">ignore_feats</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">baseline_model</span> <span class="o">=</span> <span class="n">baseline_model</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span> <span class="o">=</span> <span class="n">eval_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predict_fn</span> <span class="o">=</span> <span class="n">predict_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_predictions</span> <span class="o">=</span> <span class="n">test_predictions</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encode_cat_feats</span> <span class="o">=</span> <span class="n">encode_cat_feats</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale_num_feats</span> <span class="o">=</span> <span class="n">scale_num_feats</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_schema_custom_feature_map</span> <span class="o">=</span> <span class="n">schema_custom_feature_map</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_schema</span> <span class="o">=</span> <span class="n">dataset_schema</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">metric_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric_baseline_model</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mercury.robust.model_tests.TreeCoverageTest" class="doc doc-heading">
              <code class=" language-python"><span class="n">TreeCoverageTest</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">threshold_coverage</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mercury.robust.basetests.RobustModelTest">RobustModelTest</span></code></p>


        <p>This test checks whether a given test_dataset covers a minimum percentage of all the branches of
a tree. Use this in case you want to make sure no leaves are left unexplored when testing your model.
In case the percentage of coverage is less than the required <code>threshold_coverage</code>, the test will fail.</p>
<p>Right now, this test only supports scikit-learn tree models, including sklearn pipelines with one tree
model in one of its steps.</p>
<p>TODO: Add support for other frameworks such as lightgbm, catboost or xgboost.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="sklearn.tree.DecisionTreeClassifier">DecisionTreeClassifier</span>, <span title="sklearn.tree.DecisionTreeRegressor">DecisionTreeRegressor</span>, <span title="sklearn.ensemble.RandomForestClassifier">RandomForestClassifier</span>, <span title="sklearn.ensemble.RandomForestRegressor">RandomForestRegressor</span>, <span title="sklearn.pipeline.Pipeline">Pipeline</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fitted tree-based model (or sklearn pipeline with a tree-based model) to inspect</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>test_dataset</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataset for testing the coverage.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>threshold_coverage</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>this threshold represents the minimum percentage that the <code>test_dataset</code> needs
to cover in order to pass the test. Eg. if <code>threshold_coverage=0.7</code> then the <code>test_dataset</code>
needs to cover at least 70% of the branches to pass the test.</p>
              </div>
            </td>
            <td>
                  <code>0.7</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A name for the test. If not used, it will take the name of the class.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">testing_dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">TreeCoverageTest</span><span class="p">(</span>
<span class="o">...</span>    <span class="n">rf</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">testing_dataset</span><span class="p">,</span>
<span class="o">...</span>    <span class="n">threshold_coverage</span><span class="o">=</span><span class="mf">.8</span>
<span class="o">...</span>    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;My Tree Coverage Test&quot;</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>  <span class="c1"># The test will fail if the obtained coverage is less than 80%</span>
</code></pre></div>
</details>





                  <details class="quote">
                    <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
                    <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;DecisionTreeClassifier&quot;</span><span class="p">,</span> <span class="s2">&quot;DecisionTreeRegressor&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;RandomForestClassifier&quot;</span><span class="p">,</span> <span class="s2">&quot;RandomForestRegressor&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;sklearn.pipeline.Pipeline&quot;</span><span class="p">],</span>  <span class="c1"># noqa: F821</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="s2">&quot;pd.DataFrame&quot;</span><span class="p">,</span>  <span class="c1"># noqa: F821,</span>
    <span class="n">threshold_coverage</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">.7</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_coverage</span> <span class="o">=</span> <span class="n">threshold_coverage</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
        <span class="n">index_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_identify_tree_in_pipeline</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_pipeline_until_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">index_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">steps</span><span class="p">[</span><span class="n">index_model</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_analyzer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_analyzer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coverage</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mercury.robust.model_tests.TreeCoverageTest.run" class="doc doc-heading">
            <code class=" language-python"><span class="n">run</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Run the test</p>

            <details class="quote">
              <summary>Source code in <code>mercury/robust/model_tests.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run the test&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">)</span>
    <span class="n">coverage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_analyzer</span><span class="o">.</span><span class="n">get_percent_coverage</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coverage</span> <span class="o">=</span> <span class="n">coverage</span>

    <span class="k">if</span> <span class="n">coverage</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_coverage</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">FailedTestError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Achieved a coverage of </span><span class="si">{</span><span class="n">coverage</span><span class="si">}</span><span class="s2"> while the minimum required was </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_coverage</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["tabs", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>